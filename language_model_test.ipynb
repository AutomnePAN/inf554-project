{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-19e49e256bba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow_hub\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhub\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tf'"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow\n",
    "import tensorflow_hub as hub\n",
    "from tf.keras import metrics\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "from verstack.stratified_continuous_split import scsplit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need some time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity:  0.7514804\n",
      "Similarity:  0.06448189\n",
      "Similarity:  0.4482424\n"
     ]
    }
   ],
   "source": [
    "# test the language model\n",
    "\n",
    "phrases_embed = embed([\"The capital of France is Paris\", \"Paris is the biggest french city\"])\n",
    "print( \"Similarity: \", ( sum( phrases_embed[0] * phrases_embed[1] ).numpy() ) )\n",
    "\n",
    "phrases_embed = embed([\"The capital of France is Paris\", \"I would like some coffee\"])\n",
    "print( \"Similarity: \", sum( phrases_embed[0] * phrases_embed[1] ).numpy() )\n",
    "\n",
    "phrases_embed = embed([\"Some black tea with sugar, please\", \"I would like some coffee\"])\n",
    "print( \"Similarity: \", sum( phrases_embed[0] * phrases_embed[1] ).numpy() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210088                                           CALLED IT.\n",
      "353448    first, manufacture the evidence, sell it to al...\n",
      "110884    The best part of Trump‚Äôs Fox News town hall is...\n",
      "118100    Because it‚Äôs Africa...the world won‚Äôt take it ...\n",
      "213235    Troubling development out of Trousdale Correct...\n",
      "41954                                             Ya think.\n",
      "493307               This is so sad! He was the best of us.\n",
      "99564                                     2020 is fucked up\n",
      "248579     The rich are getting richer off the Corona Virus\n",
      "377307    How long until we admit coronavirus has direct...\n",
      "Name: text, dtype: object\n",
      "tf.Tensor(\n",
      "[[ 0.00281394  0.00676178  0.00043603 ... -0.01381203  0.01512007\n",
      "   0.00630505]\n",
      " [-0.01473356 -0.06944113  0.0046551  ... -0.00106915 -0.0253217\n",
      "  -0.01710856]\n",
      " [ 0.00447236 -0.00602912 -0.03080316 ... -0.00867151 -0.0626659\n",
      "   0.05444583]\n",
      " ...\n",
      " [-0.06370888 -0.06671701  0.00352778 ... -0.02371787  0.00076623\n",
      "  -0.02998426]\n",
      " [ 0.01011501 -0.04472246  0.01779229 ... -0.05217279 -0.03629337\n",
      "  -0.06184245]\n",
      " [ 0.00451679 -0.04017515 -0.06433453 ...  0.00942981  0.00769876\n",
      "   0.00191677]], shape=(10, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"./data/train.csv\")\n",
    "X_train, X_test, y_train, y_test = scsplit(train_data, train_data['retweet_count'], stratify=train_data['retweet_count'], train_size=0.75, test_size=0.25)\n",
    "X_train = X_train.drop(['retweet_count'], axis=1)\n",
    "X_test = X_test.drop(['retweet_count'], axis=1)\n",
    "\n",
    "X_train = X_train[\"text\"]\n",
    "X_test = X_test[\"text\"]\n",
    "print(X_train[:10])\n",
    "print(embed(X_train[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed the Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CALLED IT.',\n",
       "       'first, manufacture the evidence, sell it to all the frauds, compare notes with each other, and call it verified.',\n",
       "       'The best part of Trump‚Äôs Fox News town hall is the long commercial breaks.',\n",
       "       ...,\n",
       "       'On the front line - Taoiseach @LeoVaradkar at Morgans Place site in Blachardstown where he he help with #Covid19 testing of residents. This sends out a really positive message üëèüèªüëèüèªüëèüèª https://t.co/neqoZ817dZ',\n",
       "       '‡Æ™‡ØÜ‡Æ∞‡ØÅ‡Æ®‡Æï‡Æ∞ ‡Æö‡ØÜ‡Æ©‡Øç‡Æ©‡Øà ‡ÆÆ‡Ææ‡Æ®‡Æï‡Æ∞‡Ææ‡Æü‡Øç‡Æö‡Æø‡ÆØ‡Æø‡Æ≤‡Øç, ‡Æï‡Øä‡Æ∞‡Øã‡Æ©‡Ææ ‡Æ™‡Ææ‡Æ§‡Æø‡Æ™‡Øç‡Æ™‡Æø‡Æ≤‡Øç ‡Æá‡Æ∞‡ØÅ‡Æ®‡Øç‡Æ§‡ØÅ ‡Æï‡ØÅ‡Æ£‡ÆÆ‡Æü‡Øà‡Æ®‡Øç‡Æ§‡Æµ‡Æ∞‡Øç‡Æï‡Æ≥‡Øç, ‡Æ§‡Æ±‡Øç‡Æ™‡Øã‡Æ§‡ØÅ ‡Æö‡Æø‡Æï‡Æø‡Æö‡Øç‡Æö‡Øà ‡Æ™‡ØÜ‡Æ∞‡ØÅ‡Æ™‡Æµ‡Æ∞‡Øç‡Æï‡Æ≥‡Æø‡Æ©‡Øç ‡ÆÆ‡Æ£‡Øç‡Æü‡Æ≤‡Æµ‡Ææ‡Æ∞‡Æø ‡Æµ‡Æø‡Æµ‡Æ∞‡ÆÆ‡Øç #polimer #polimernews #coronavirus #Covid19 #GreaterChennaiCorporation https://t.co/ZWeX88fALk',\n",
       "       '#Ofcom are a joke not fit for purpose what did they do about #FakeNews at the #BBC to justify bombing #Syria and #Iraq? If #5G turns out to be unsafe and people are harmed this woman and Ofcom will be finished. #NHS #BarCouncil #MisconductinPublicOffice #coronavirus #Rothschild https://t.co/c2mMOWFSxN'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "499332"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_embed = np.zeros( (X_train.shape[0], 512) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n",
      "134000\n",
      "135000\n",
      "136000\n",
      "137000\n",
      "138000\n",
      "139000\n",
      "140000\n",
      "141000\n",
      "142000\n",
      "143000\n",
      "144000\n",
      "145000\n",
      "146000\n",
      "147000\n",
      "148000\n",
      "149000\n",
      "150000\n",
      "151000\n",
      "152000\n",
      "153000\n",
      "154000\n",
      "155000\n",
      "156000\n",
      "157000\n",
      "158000\n",
      "159000\n",
      "160000\n",
      "161000\n",
      "162000\n",
      "163000\n",
      "164000\n",
      "165000\n",
      "166000\n",
      "167000\n",
      "168000\n",
      "169000\n",
      "170000\n",
      "171000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-8a098386dedc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m1000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mX_train_embed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36m_call_attribute\u001b[1;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_call_attribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    604\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 606\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    607\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for index, x in enumerate(X_train):\n",
    "    if index % 1000 == 0:\n",
    "        print(index)\n",
    "    X_train_embed[index, :] = embed([x]).numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_embed = X_train_embed[:10000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 512)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0, 89, ...,  0,  0,  1], dtype=int64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build up the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, 'relu'))\n",
    "    model.compile(loss=\"mse\", optimizer='adam', metrics=[\"mse\"])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00281393,  0.0067618 ,  0.00043604, ..., -0.01381206,\n",
       "         0.01512006,  0.00630507],\n",
       "       [-0.01473355, -0.06944113,  0.00465509, ..., -0.00106913,\n",
       "        -0.02532168, -0.01710855],\n",
       "       [ 0.00447234, -0.00602915, -0.03080317, ..., -0.00867152,\n",
       "        -0.06266589,  0.05444582],\n",
       "       ...,\n",
       "       [-0.04201492,  0.03147441,  0.03473513, ...,  0.06916818,\n",
       "         0.00319515, -0.1078413 ],\n",
       "       [-0.07394182, -0.00274012,  0.08254025, ..., -0.05593901,\n",
       "        -0.02026385, -0.02183842],\n",
       "       [ 0.01431507,  0.06577744, -0.00417293, ..., -0.02583069,\n",
       "        -0.07258449, -0.04139128]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array( X_train_embed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      "8000/8000 [==============================] - 1s 158us/sample - loss: 7768035.9216 - mse: 7768036.0000 - val_loss: 1476889.8475 - val_mse: 1476889.8750\n",
      "Epoch 2/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 7709581.3765 - mse: 7709582.0000 - val_loss: 1468968.9283 - val_mse: 1468968.8750\n",
      "Epoch 3/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 7596514.0077 - mse: 7596514.0000 - val_loss: 1557479.4981 - val_mse: 1557479.3750\n",
      "Epoch 4/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 6716366.0275 - mse: 6716366.0000 - val_loss: 2400466.5145 - val_mse: 2400466.7500\n",
      "Epoch 5/50\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 2421334.1502 - mse: 2421334.0000 - val_loss: 2017700.7858 - val_mse: 2017700.7500\n",
      "Epoch 6/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 1953517.2414 - mse: 1953517.2500 - val_loss: 2235880.2734 - val_mse: 2235880.5000\n",
      "Epoch 7/50\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 1854103.0834 - mse: 1854103.2500 - val_loss: 1711913.4921 - val_mse: 1711913.6250\n",
      "Epoch 8/50\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 1712176.9827 - mse: 1712177.0000 - val_loss: 2035710.6114 - val_mse: 2035710.5000\n",
      "Epoch 9/50\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 1488086.8373 - mse: 1488086.7500 - val_loss: 3211475.3195 - val_mse: 3211475.5000\n",
      "Epoch 10/50\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 2924070.5479 - mse: 2924070.7500 - val_loss: 1471479.7252 - val_mse: 1471479.6250\n",
      "Epoch 11/50\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 5118575.4481 - mse: 5118574.5000 - val_loss: 2258913.5109 - val_mse: 2258913.2500\n",
      "Epoch 12/50\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 1958184.8408 - mse: 1958185.0000 - val_loss: 1603514.4521 - val_mse: 1603514.5000\n",
      "Epoch 13/50\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 1806484.8666 - mse: 1806484.5000 - val_loss: 1796163.4365 - val_mse: 1796163.5000\n",
      "Epoch 14/50\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 1440264.1759 - mse: 1440264.1250 - val_loss: 2798490.8218 - val_mse: 2798491.0000\n",
      "Epoch 15/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 2854355.6476 - mse: 2854355.7500 - val_loss: 1505982.2870 - val_mse: 1505982.3750\n",
      "Epoch 16/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 2672259.7357 - mse: 2672259.5000 - val_loss: 1815074.1245 - val_mse: 1815074.1250\n",
      "Epoch 17/50\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 1241989.4447 - mse: 1241989.3750 - val_loss: 2384944.9087 - val_mse: 2384945.0000\n",
      "Epoch 18/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 1749967.6430 - mse: 1749967.6250 - val_loss: 1850216.9680 - val_mse: 1850217.0000\n",
      "Epoch 19/50\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 791618.7639 - mse: 791618.6875 - val_loss: 1620572.8653 - val_mse: 1620572.7500\n",
      "Epoch 20/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 505353.8079 - mse: 505353.7500 - val_loss: 2005988.0592 - val_mse: 2005988.1250\n",
      "Epoch 21/50\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 303901.9924 - mse: 303902.0312 - val_loss: 1838039.2475 - val_mse: 1838039.2500\n",
      "Epoch 22/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 328443.7423 - mse: 328443.7500 - val_loss: 1925808.1323 - val_mse: 1925808.1250\n",
      "Epoch 23/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 295647.9783 - mse: 295648.0312 - val_loss: 2201910.4925 - val_mse: 2201910.2500\n",
      "Epoch 24/50\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 259897.1797 - mse: 259897.2031 - val_loss: 1758954.0055 - val_mse: 1758953.8750\n",
      "Epoch 25/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 250140.4977 - mse: 250140.5312 - val_loss: 2144938.3788 - val_mse: 2144938.5000\n",
      "Epoch 26/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 385649.4355 - mse: 385649.4062 - val_loss: 1960326.8566 - val_mse: 1960326.8750\n",
      "Epoch 27/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 363236.5228 - mse: 363236.5000 - val_loss: 2000695.3723 - val_mse: 2000695.3750\n",
      "Epoch 28/50\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 262698.3645 - mse: 262698.3438 - val_loss: 1767632.4217 - val_mse: 1767632.2500\n",
      "Epoch 29/50\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 237656.0381 - mse: 237656.0469 - val_loss: 1827978.2895 - val_mse: 1827978.2500\n",
      "Epoch 30/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 307243.2778 - mse: 307243.2500 - val_loss: 1969115.6198 - val_mse: 1969115.5000\n",
      "Epoch 31/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 301705.3558 - mse: 301705.3438 - val_loss: 1971690.6466 - val_mse: 1971690.5000\n",
      "Epoch 32/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 337758.1534 - mse: 337758.1875 - val_loss: 2394791.4265 - val_mse: 2394791.5000\n",
      "Epoch 33/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 937112.8052 - mse: 937112.8125 - val_loss: 2014854.6154 - val_mse: 2014854.5000\n",
      "Epoch 34/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 872373.3094 - mse: 872373.2500 - val_loss: 2217460.6110 - val_mse: 2217460.7500\n",
      "Epoch 35/50\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 1501276.4803 - mse: 1501276.2500 - val_loss: 1480820.8136 - val_mse: 1480820.8750\n",
      "Epoch 36/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 1333997.1167 - mse: 1333997.1250 - val_loss: 2209571.7540 - val_mse: 2209571.5000\n",
      "Epoch 37/50\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 763033.2759 - mse: 763033.3750 - val_loss: 1527510.7375 - val_mse: 1527510.7500\n",
      "Epoch 38/50\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 1256909.6842 - mse: 1256909.6250 - val_loss: 1633820.6854 - val_mse: 1633820.6250\n",
      "Epoch 39/50\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 758705.0097 - mse: 758705.0625 - val_loss: 1681855.0060 - val_mse: 1681855.0000\n",
      "Epoch 40/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 618396.3358 - mse: 618396.3750 - val_loss: 1802284.8926 - val_mse: 1802284.7500\n",
      "Epoch 41/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 241265.5223 - mse: 241265.5312 - val_loss: 1824819.3799 - val_mse: 1824819.3750\n",
      "Epoch 42/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 263846.4959 - mse: 263846.5000 - val_loss: 2146915.4174 - val_mse: 2146915.5000\n",
      "Epoch 43/50\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 284016.7421 - mse: 284016.7500 - val_loss: 2127242.8905 - val_mse: 2127243.0000\n",
      "Epoch 44/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 311063.9030 - mse: 311063.9375 - val_loss: 2008882.5547 - val_mse: 2008882.7500\n",
      "Epoch 45/50\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 514613.0069 - mse: 514613.0625 - val_loss: 1614506.5905 - val_mse: 1614506.6250\n",
      "Epoch 46/50\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 899725.7378 - mse: 899725.6875 - val_loss: 1978336.8477 - val_mse: 1978336.7500\n",
      "Epoch 47/50\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 539271.9107 - mse: 539272.0000 - val_loss: 1837938.6295 - val_mse: 1837938.3750\n",
      "Epoch 48/50\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 256560.0046 - mse: 256560.0156 - val_loss: 2079745.3906 - val_mse: 2079745.3750\n",
      "Epoch 49/50\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 169854.0426 - mse: 169854.0469 - val_loss: 1890362.2233 - val_mse: 1890362.0000\n",
      "Epoch 50/50\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 316351.5085 - mse: 316351.5000 - val_loss: 1668635.0632 - val_mse: 1668635.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19dc5767518>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.fit(X_train_embed, y_train, epochs=epochs, batch_size = batch_size, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_74 (Dense)             multiple                  131328    \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             multiple                  257       \n",
      "=================================================================\n",
      "Total params: 526,337\n",
      "Trainable params: 526,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 16 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 16 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[15.925902]], dtype=float32)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[X_train_embed[2]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.3975"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-2.61 * 1.37 + 1.37*0.86"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
