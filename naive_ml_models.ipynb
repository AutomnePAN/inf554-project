{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the modules used\n",
    "\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow\n",
    "import tensorflow_hub as hub\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "from verstack.stratified_continuous_split import scsplit\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_cut(word):\n",
    "    if pd.isna(word):\n",
    "        return []\n",
    "    word_array = np.array([])\n",
    "    l = 0\n",
    "    for i,s in enumerate(word):\n",
    "        if s == ',':\n",
    "            word_array = np.append(word_array, word[l:i])\n",
    "            l = i+1\n",
    "    word_array = np.append(word_array, word[l::])\n",
    "    return word_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter(word):\n",
    "    if pd.isna(word):\n",
    "        return 0\n",
    "    number = 1\n",
    "    for s in word:\n",
    "        if s == ',':\n",
    "            number += 1\n",
    "    return number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(df):\n",
    "    df = pd.read_csv(\"data/train.csv\")\n",
    "    df[\"user_verified\"] = df[\"user_verified\"].astype(int)\n",
    "    df['date']  =(df['timestamp']).astype(np.int64) // 10**3\n",
    "    df[\"user_verified\"] = df[\"user_verified\"].astype(int)\n",
    "    df['date']= pd.to_datetime(df['date'], unit='s')\n",
    "    df[\"hour\"] = df[\"date\"].dt.hour\n",
    "    df[\"day\"] = df[\"date\"].dt.day\n",
    "    df[\"month\"] = df[\"date\"].dt.month\n",
    "\n",
    "    # 0 for Monday\n",
    "    df[\"weekday\"] = df[\"date\"].dt.weekday\n",
    "\n",
    "    # If the day is a weekend or not\n",
    "    df[\"weekend\"] = np.where(np.logical_or(df[\"weekday\"] == 5, df[\"weekday\"] == 6), 1, 0)\n",
    "    df[\"friends_followers_ratio\"] = df[\"user_friends_count\"]/df[\"user_followers_count\"]\n",
    "    df[\"has_hashtags\"] = np.where(pd.notnull(df[\"hashtags\"]), 1, 0)\n",
    "    df[\"has_mentions\"] = np.where(pd.notnull(df[\"user_mentions\"]), 1, 0)\n",
    "    df[\"has_urls\"] = np.where(pd.notnull(df[\"urls\"]), 1, 0)\n",
    "\n",
    "    df[\"number_of_urls\"] = df[\"urls\"].apply(counter)\n",
    "    df[\"number_of_mentions\"] = df[\"user_mentions\"].apply(counter)\n",
    "    df[\"number_of_hashtags\"] = df[\"hashtags\"].apply(counter)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_raw = pd.read_csv(\"./data/partially_treated_train_data.csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_original = pd.read_csv(\"./data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>urls</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>...</th>\n",
       "      <th>has_mentions</th>\n",
       "      <th>has_urls</th>\n",
       "      <th>number_of_urls</th>\n",
       "      <th>number_of_mentions</th>\n",
       "      <th>number_of_hashtags</th>\n",
       "      <th>urls_popularity</th>\n",
       "      <th>hashtags_popularity</th>\n",
       "      <th>mentions_popularity</th>\n",
       "      <th>mentions_max_followers</th>\n",
       "      <th>mentions_max_friends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1588696955143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>68460</td>\n",
       "      <td>1101</td>\n",
       "      <td>1226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1588464948124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>309</td>\n",
       "      <td>51</td>\n",
       "      <td>202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1588634673360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3241</td>\n",
       "      <td>1675</td>\n",
       "      <td>2325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1588433158672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>32327</td>\n",
       "      <td>667</td>\n",
       "      <td>304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1588582751599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>581</td>\n",
       "      <td>42</td>\n",
       "      <td>127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      timestamp  retweet_count  user_verified  user_statuses_count  \\\n",
       "0   0  1588696955143            0.0              0                68460   \n",
       "1   1  1588464948124            0.0              0                  309   \n",
       "2   2  1588634673360            0.0              0                 3241   \n",
       "3   3  1588433158672            0.0              0                32327   \n",
       "4   4  1588582751599            0.0              0                  581   \n",
       "\n",
       "   user_followers_count  user_friends_count user_mentions urls hashtags  ...  \\\n",
       "0                  1101                1226           NaN  NaN      NaN  ...   \n",
       "1                    51                 202           NaN  NaN      NaN  ...   \n",
       "2                  1675                2325           NaN  NaN      NaN  ...   \n",
       "3                   667                 304           NaN  NaN      NaN  ...   \n",
       "4                    42                 127           NaN  NaN      NaN  ...   \n",
       "\n",
       "  has_mentions  has_urls  number_of_urls  number_of_mentions  \\\n",
       "0            0         0               0                   0   \n",
       "1            0         0               0                   0   \n",
       "2            0         0               0                   0   \n",
       "3            0         0               0                   0   \n",
       "4            0         0               0                   0   \n",
       "\n",
       "   number_of_hashtags  urls_popularity  hashtags_popularity  \\\n",
       "0                   0                0                    0   \n",
       "1                   0                0                    0   \n",
       "2                   0                0                    0   \n",
       "3                   0                0                    0   \n",
       "4                   0                0                    0   \n",
       "\n",
       "   mentions_popularity  mentions_max_followers  mentions_max_friends  \n",
       "0                    0                     NaN                   NaN  \n",
       "1                    0                     NaN                   NaN  \n",
       "2                    0                     NaN                   NaN  \n",
       "3                    0                     NaN                   NaN  \n",
       "4                    0                     NaN                   NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_preprocess(train_data_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>urls</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>...</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weekend</th>\n",
       "      <th>friends_followers_ratio</th>\n",
       "      <th>has_hashtags</th>\n",
       "      <th>has_mentions</th>\n",
       "      <th>has_urls</th>\n",
       "      <th>number_of_urls</th>\n",
       "      <th>number_of_mentions</th>\n",
       "      <th>number_of_hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1588696955143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68460</td>\n",
       "      <td>1101</td>\n",
       "      <td>1226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.113533</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1588464948124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>309</td>\n",
       "      <td>51</td>\n",
       "      <td>202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3.960784</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1588634673360</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3241</td>\n",
       "      <td>1675</td>\n",
       "      <td>2325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.388060</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1588433158672</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32327</td>\n",
       "      <td>667</td>\n",
       "      <td>304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455772</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1588582751599</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>581</td>\n",
       "      <td>42</td>\n",
       "      <td>127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.023810</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      timestamp  retweet_count  user_verified  user_statuses_count  \\\n",
       "0   0  1588696955143              0              0                68460   \n",
       "1   1  1588464948124              0              0                  309   \n",
       "2   2  1588634673360              0              0                 3241   \n",
       "3   3  1588433158672              0              0                32327   \n",
       "4   4  1588582751599              0              0                  581   \n",
       "\n",
       "   user_followers_count  user_friends_count user_mentions urls hashtags  ...  \\\n",
       "0                  1101                1226           NaN  NaN      NaN  ...   \n",
       "1                    51                 202           NaN  NaN      NaN  ...   \n",
       "2                  1675                2325           NaN  NaN      NaN  ...   \n",
       "3                   667                 304           NaN  NaN      NaN  ...   \n",
       "4                    42                 127           NaN  NaN      NaN  ...   \n",
       "\n",
       "  month weekday  weekend  friends_followers_ratio  has_hashtags  has_mentions  \\\n",
       "0     5       1        0                 1.113533             0             0   \n",
       "1     5       6        1                 3.960784             0             0   \n",
       "2     5       0        0                 1.388060             0             0   \n",
       "3     5       5        1                 0.455772             0             0   \n",
       "4     5       0        0                 3.023810             0             0   \n",
       "\n",
       "   has_urls  number_of_urls  number_of_mentions  number_of_hashtags  \n",
       "0         0               0                   0                   0  \n",
       "1         0               0                   0                   0  \n",
       "2         0               0                   0                   0  \n",
       "3         0               0                   0                   0  \n",
       "4         0               0                   0                   0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the training features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'timestamp', 'retweet_count', 'user_verified',\n",
       "       'user_statuses_count', 'user_followers_count', 'user_friends_count',\n",
       "       'user_mentions', 'urls', 'hashtags', 'date', 'hour', 'day', 'month',\n",
       "       'weekday', 'weekend', 'friends_followers_ratio', 'has_hashtags',\n",
       "       'has_mentions', 'has_urls', 'number_of_urls', 'number_of_mentions',\n",
       "       'number_of_hashtags', 'urls_popularity', 'hashtags_popularity',\n",
       "       'mentions_popularity', 'mentions_max_followers',\n",
       "       'mentions_max_friends'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "training_features = [ 'retweet_count', 'user_verified',\n",
    "                       'user_statuses_count', 'user_followers_count', 'user_friends_count','hour', 'day', 'month',\n",
    "                       'weekday', 'weekend', 'friends_followers_ratio', 'has_hashtags',\n",
    "                       'has_mentions', 'has_urls', 'number_of_urls', 'number_of_mentions',\n",
    "                       'number_of_hashtags', 'urls_popularity', 'hashtags_popularity',\n",
    "                       'mentions_popularity', 'mentions_max_followers',\n",
    "                       'mentions_max_friends' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = train_data_raw[training_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = train_data.replace([np.inf, np.inf], 0)\n",
    "train_data = train_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weekend</th>\n",
       "      <th>...</th>\n",
       "      <th>has_mentions</th>\n",
       "      <th>has_urls</th>\n",
       "      <th>number_of_urls</th>\n",
       "      <th>number_of_mentions</th>\n",
       "      <th>number_of_hashtags</th>\n",
       "      <th>urls_popularity</th>\n",
       "      <th>hashtags_popularity</th>\n",
       "      <th>mentions_popularity</th>\n",
       "      <th>mentions_max_followers</th>\n",
       "      <th>mentions_max_friends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>665777.000000</td>\n",
       "      <td>665777.000000</td>\n",
       "      <td>6.657770e+05</td>\n",
       "      <td>6.657770e+05</td>\n",
       "      <td>6.657770e+05</td>\n",
       "      <td>665777.000000</td>\n",
       "      <td>665777.000000</td>\n",
       "      <td>665777.000000</td>\n",
       "      <td>665777.000000</td>\n",
       "      <td>665777.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>665777.000000</td>\n",
       "      <td>665777.000000</td>\n",
       "      <td>665777.000000</td>\n",
       "      <td>665777.000000</td>\n",
       "      <td>665777.000000</td>\n",
       "      <td>665777.000000</td>\n",
       "      <td>665777.000000</td>\n",
       "      <td>665777.000000</td>\n",
       "      <td>5.429100e+04</td>\n",
       "      <td>5.429100e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>147.687398</td>\n",
       "      <td>0.133294</td>\n",
       "      <td>4.167295e+04</td>\n",
       "      <td>2.329881e+05</td>\n",
       "      <td>2.743131e+03</td>\n",
       "      <td>12.646503</td>\n",
       "      <td>4.067243</td>\n",
       "      <td>4.959878</td>\n",
       "      <td>2.983509</td>\n",
       "      <td>0.286012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081545</td>\n",
       "      <td>0.321549</td>\n",
       "      <td>0.330758</td>\n",
       "      <td>0.129498</td>\n",
       "      <td>0.192219</td>\n",
       "      <td>62055.176618</td>\n",
       "      <td>888.411818</td>\n",
       "      <td>8.950151</td>\n",
       "      <td>7.029292e+06</td>\n",
       "      <td>2.747307e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2972.051181</td>\n",
       "      <td>0.339892</td>\n",
       "      <td>9.848516e+04</td>\n",
       "      <td>2.442260e+06</td>\n",
       "      <td>1.725410e+04</td>\n",
       "      <td>7.030982</td>\n",
       "      <td>5.507782</td>\n",
       "      <td>0.196244</td>\n",
       "      <td>2.206916</td>\n",
       "      <td>0.451895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273671</td>\n",
       "      <td>0.467071</td>\n",
       "      <td>0.490239</td>\n",
       "      <td>0.558951</td>\n",
       "      <td>0.694312</td>\n",
       "      <td>105870.928890</td>\n",
       "      <td>4271.525566</td>\n",
       "      <td>118.361516</td>\n",
       "      <td>2.085563e+07</td>\n",
       "      <td>2.518922e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.352000e+03</td>\n",
       "      <td>2.060000e+02</td>\n",
       "      <td>2.290000e+02</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.080400e+04</td>\n",
       "      <td>1.002000e+03</td>\n",
       "      <td>6.390000e+02</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.809900e+04</td>\n",
       "      <td>6.012000e+03</td>\n",
       "      <td>1.746000e+03</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>242936.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.892020e+05</td>\n",
       "      <td>7.020000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>942572.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.203222e+06</td>\n",
       "      <td>1.170640e+08</td>\n",
       "      <td>4.399078e+06</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>242936.000000</td>\n",
       "      <td>25490.000000</td>\n",
       "      <td>2239.000000</td>\n",
       "      <td>1.267528e+08</td>\n",
       "      <td>1.392825e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       retweet_count  user_verified  user_statuses_count  \\\n",
       "count  665777.000000  665777.000000         6.657770e+05   \n",
       "mean      147.687398       0.133294         4.167295e+04   \n",
       "std      2972.051181       0.339892         9.848516e+04   \n",
       "min         0.000000       0.000000         0.000000e+00   \n",
       "25%         0.000000       0.000000         2.352000e+03   \n",
       "50%         0.000000       0.000000         1.080400e+04   \n",
       "75%         2.000000       0.000000         3.809900e+04   \n",
       "max    942572.000000       1.000000         7.203222e+06   \n",
       "\n",
       "       user_followers_count  user_friends_count           hour            day  \\\n",
       "count          6.657770e+05        6.657770e+05  665777.000000  665777.000000   \n",
       "mean           2.329881e+05        2.743131e+03      12.646503       4.067243   \n",
       "std            2.442260e+06        1.725410e+04       7.030982       5.507782   \n",
       "min            0.000000e+00        0.000000e+00       0.000000       1.000000   \n",
       "25%            2.060000e+02        2.290000e+02       7.000000       1.000000   \n",
       "50%            1.002000e+03        6.390000e+02      14.000000       3.000000   \n",
       "75%            6.012000e+03        1.746000e+03      19.000000       5.000000   \n",
       "max            1.170640e+08        4.399078e+06      23.000000      30.000000   \n",
       "\n",
       "               month        weekday        weekend  ...   has_mentions  \\\n",
       "count  665777.000000  665777.000000  665777.000000  ...  665777.000000   \n",
       "mean        4.959878       2.983509       0.286012  ...       0.081545   \n",
       "std         0.196244       2.206916       0.451895  ...       0.273671   \n",
       "min         4.000000       0.000000       0.000000  ...       0.000000   \n",
       "25%         5.000000       1.000000       0.000000  ...       0.000000   \n",
       "50%         5.000000       4.000000       0.000000  ...       0.000000   \n",
       "75%         5.000000       5.000000       1.000000  ...       0.000000   \n",
       "max         5.000000       6.000000       1.000000  ...       1.000000   \n",
       "\n",
       "            has_urls  number_of_urls  number_of_mentions  number_of_hashtags  \\\n",
       "count  665777.000000   665777.000000       665777.000000       665777.000000   \n",
       "mean        0.321549        0.330758            0.129498            0.192219   \n",
       "std         0.467071        0.490239            0.558951            0.694312   \n",
       "min         0.000000        0.000000            0.000000            0.000000   \n",
       "25%         0.000000        0.000000            0.000000            0.000000   \n",
       "50%         0.000000        0.000000            0.000000            0.000000   \n",
       "75%         1.000000        1.000000            0.000000            0.000000   \n",
       "max         1.000000        5.000000           13.000000           18.000000   \n",
       "\n",
       "       urls_popularity  hashtags_popularity  mentions_popularity  \\\n",
       "count    665777.000000        665777.000000        665777.000000   \n",
       "mean      62055.176618           888.411818             8.950151   \n",
       "std      105870.928890          4271.525566           118.361516   \n",
       "min           0.000000             0.000000             0.000000   \n",
       "25%           0.000000             0.000000             0.000000   \n",
       "50%           0.000000             0.000000             0.000000   \n",
       "75%      242936.000000             0.000000             0.000000   \n",
       "max      242936.000000         25490.000000          2239.000000   \n",
       "\n",
       "       mentions_max_followers  mentions_max_friends  \n",
       "count            5.429100e+04          5.429100e+04  \n",
       "mean             7.029292e+06          2.747307e+03  \n",
       "std              2.085563e+07          2.518922e+04  \n",
       "min              0.000000e+00          0.000000e+00  \n",
       "25%              0.000000e+00          0.000000e+00  \n",
       "50%              0.000000e+00          0.000000e+00  \n",
       "75%              7.892020e+05          7.020000e+02  \n",
       "max              1.267528e+08          1.392825e+06  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weekend</th>\n",
       "      <th>...</th>\n",
       "      <th>has_mentions</th>\n",
       "      <th>has_urls</th>\n",
       "      <th>number_of_urls</th>\n",
       "      <th>number_of_mentions</th>\n",
       "      <th>number_of_hashtags</th>\n",
       "      <th>urls_popularity</th>\n",
       "      <th>hashtags_popularity</th>\n",
       "      <th>mentions_popularity</th>\n",
       "      <th>mentions_max_followers</th>\n",
       "      <th>mentions_max_friends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>68460</td>\n",
       "      <td>1101</td>\n",
       "      <td>1226</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>309</td>\n",
       "      <td>51</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3241</td>\n",
       "      <td>1675</td>\n",
       "      <td>2325</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>32327</td>\n",
       "      <td>667</td>\n",
       "      <td>304</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>581</td>\n",
       "      <td>42</td>\n",
       "      <td>127</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   retweet_count  user_verified  user_statuses_count  user_followers_count  \\\n",
       "0            0.0              0                68460                  1101   \n",
       "1            0.0              0                  309                    51   \n",
       "2            0.0              0                 3241                  1675   \n",
       "3            0.0              0                32327                   667   \n",
       "4            0.0              0                  581                    42   \n",
       "\n",
       "   user_friends_count  hour  day  month  weekday  weekend  ...  has_mentions  \\\n",
       "0                1226    16    5      5        1        0  ...             0   \n",
       "1                 202     0    3      5        6        1  ...             0   \n",
       "2                2325    23    4      5        0        0  ...             0   \n",
       "3                 304    15    2      5        5        1  ...             0   \n",
       "4                 127     8    4      5        0        0  ...             0   \n",
       "\n",
       "   has_urls  number_of_urls  number_of_mentions  number_of_hashtags  \\\n",
       "0         0               0                   0                   0   \n",
       "1         0               0                   0                   0   \n",
       "2         0               0                   0                   0   \n",
       "3         0               0                   0                   0   \n",
       "4         0               0                   0                   0   \n",
       "\n",
       "   urls_popularity  hashtags_popularity  mentions_popularity  \\\n",
       "0                0                    0                    0   \n",
       "1                0                    0                    0   \n",
       "2                0                    0                    0   \n",
       "3                0                    0                    0   \n",
       "4                0                    0                    0   \n",
       "\n",
       "   mentions_max_followers  mentions_max_friends  \n",
       "0                     0.0                   0.0  \n",
       "1                     0.0                   0.0  \n",
       "2                     0.0                   0.0  \n",
       "3                     0.0                   0.0  \n",
       "4                     0.0                   0.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weekend</th>\n",
       "      <th>...</th>\n",
       "      <th>has_mentions</th>\n",
       "      <th>has_urls</th>\n",
       "      <th>number_of_urls</th>\n",
       "      <th>number_of_mentions</th>\n",
       "      <th>number_of_hashtags</th>\n",
       "      <th>urls_popularity</th>\n",
       "      <th>hashtags_popularity</th>\n",
       "      <th>mentions_popularity</th>\n",
       "      <th>mentions_max_followers</th>\n",
       "      <th>mentions_max_friends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>546442</th>\n",
       "      <td>942572.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12256</td>\n",
       "      <td>25441659</td>\n",
       "      <td>133</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        retweet_count  user_verified  user_statuses_count  \\\n",
       "546442       942572.0              1                12256   \n",
       "\n",
       "        user_followers_count  user_friends_count  hour  day  month  weekday  \\\n",
       "546442              25441659                 133    13    4      5        0   \n",
       "\n",
       "        weekend  ...  has_mentions  has_urls  number_of_urls  \\\n",
       "546442        0  ...             0         0               0   \n",
       "\n",
       "        number_of_mentions  number_of_hashtags  urls_popularity  \\\n",
       "546442                   0                   0                0   \n",
       "\n",
       "        hashtags_popularity  mentions_popularity  mentions_max_followers  \\\n",
       "546442                    0                    0                     0.0   \n",
       "\n",
       "        mentions_max_friends  \n",
       "546442                   0.0  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data['retweet_count'] > 900000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "retweet_count              0\n",
       "user_verified              0\n",
       "user_statuses_count        0\n",
       "user_followers_count       0\n",
       "user_friends_count         0\n",
       "hour                       0\n",
       "day                        0\n",
       "month                      0\n",
       "weekday                    0\n",
       "weekend                    0\n",
       "friends_followers_ratio    0\n",
       "has_hashtags               0\n",
       "has_mentions               0\n",
       "has_urls                   0\n",
       "number_of_urls             0\n",
       "number_of_mentions         0\n",
       "number_of_hashtags         0\n",
       "urls_popularity            0\n",
       "hashtags_popularity        0\n",
       "mentions_popularity        0\n",
       "mentions_max_followers     0\n",
       "mentions_max_friends       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop the rows with `NaN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['retweet_count', 'user_verified', 'user_statuses_count',\n",
       "       'user_followers_count', 'user_friends_count', 'hour', 'day', 'month',\n",
       "       'weekday', 'weekend', 'friends_followers_ratio', 'has_hashtags',\n",
       "       'has_mentions', 'has_urls', 'number_of_urls', 'number_of_mentions',\n",
       "       'number_of_hashtags', 'urls_popularity', 'hashtags_popularity',\n",
       "       'mentions_popularity', 'mentions_max_followers',\n",
       "       'mentions_max_friends'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weekend</th>\n",
       "      <th>friends_followers_ratio</th>\n",
       "      <th>has_hashtags</th>\n",
       "      <th>has_mentions</th>\n",
       "      <th>has_urls</th>\n",
       "      <th>number_of_urls</th>\n",
       "      <th>number_of_mentions</th>\n",
       "      <th>number_of_hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>664949.000000</td>\n",
       "      <td>664949.000000</td>\n",
       "      <td>6.649490e+05</td>\n",
       "      <td>6.649490e+05</td>\n",
       "      <td>6.649490e+05</td>\n",
       "      <td>664949.000000</td>\n",
       "      <td>664949.000000</td>\n",
       "      <td>664949.000000</td>\n",
       "      <td>664949.000000</td>\n",
       "      <td>664949.000000</td>\n",
       "      <td>664949.000000</td>\n",
       "      <td>664949.000000</td>\n",
       "      <td>664949.000000</td>\n",
       "      <td>664949.000000</td>\n",
       "      <td>664949.000000</td>\n",
       "      <td>664949.000000</td>\n",
       "      <td>664949.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>147.864854</td>\n",
       "      <td>0.133460</td>\n",
       "      <td>4.172351e+04</td>\n",
       "      <td>2.332783e+05</td>\n",
       "      <td>2.746547e+03</td>\n",
       "      <td>12.647690</td>\n",
       "      <td>4.068020</td>\n",
       "      <td>4.959848</td>\n",
       "      <td>2.983378</td>\n",
       "      <td>0.285923</td>\n",
       "      <td>2.196596</td>\n",
       "      <td>0.108908</td>\n",
       "      <td>0.081600</td>\n",
       "      <td>0.321817</td>\n",
       "      <td>0.331013</td>\n",
       "      <td>0.129583</td>\n",
       "      <td>0.192349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2973.892555</td>\n",
       "      <td>0.340071</td>\n",
       "      <td>9.853563e+04</td>\n",
       "      <td>2.443767e+06</td>\n",
       "      <td>1.726456e+04</td>\n",
       "      <td>7.030958</td>\n",
       "      <td>5.509663</td>\n",
       "      <td>0.196316</td>\n",
       "      <td>2.206798</td>\n",
       "      <td>0.451853</td>\n",
       "      <td>7.568688</td>\n",
       "      <td>0.311523</td>\n",
       "      <td>0.273755</td>\n",
       "      <td>0.467174</td>\n",
       "      <td>0.490283</td>\n",
       "      <td>0.559090</td>\n",
       "      <td>0.694441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.368000e+03</td>\n",
       "      <td>2.070000e+02</td>\n",
       "      <td>2.300000e+02</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.083500e+04</td>\n",
       "      <td>1.006000e+03</td>\n",
       "      <td>6.410000e+02</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.932579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.815400e+04</td>\n",
       "      <td>6.031000e+03</td>\n",
       "      <td>1.749000e+03</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.900338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>942572.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.203222e+06</td>\n",
       "      <td>1.170640e+08</td>\n",
       "      <td>4.399078e+06</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1915.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       retweet_count  user_verified  user_statuses_count  \\\n",
       "count  664949.000000  664949.000000         6.649490e+05   \n",
       "mean      147.864854       0.133460         4.172351e+04   \n",
       "std      2973.892555       0.340071         9.853563e+04   \n",
       "min         0.000000       0.000000         1.000000e+00   \n",
       "25%         0.000000       0.000000         2.368000e+03   \n",
       "50%         0.000000       0.000000         1.083500e+04   \n",
       "75%         2.000000       0.000000         3.815400e+04   \n",
       "max    942572.000000       1.000000         7.203222e+06   \n",
       "\n",
       "       user_followers_count  user_friends_count           hour            day  \\\n",
       "count          6.649490e+05        6.649490e+05  664949.000000  664949.000000   \n",
       "mean           2.332783e+05        2.746547e+03      12.647690       4.068020   \n",
       "std            2.443767e+06        1.726456e+04       7.030958       5.509663   \n",
       "min            0.000000e+00        0.000000e+00       0.000000       1.000000   \n",
       "25%            2.070000e+02        2.300000e+02       7.000000       1.000000   \n",
       "50%            1.006000e+03        6.410000e+02      14.000000       3.000000   \n",
       "75%            6.031000e+03        1.749000e+03      19.000000       5.000000   \n",
       "max            1.170640e+08        4.399078e+06      23.000000      30.000000   \n",
       "\n",
       "               month        weekday        weekend  friends_followers_ratio  \\\n",
       "count  664949.000000  664949.000000  664949.000000            664949.000000   \n",
       "mean        4.959848       2.983378       0.285923                 2.196596   \n",
       "std         0.196316       2.206798       0.451853                 7.568688   \n",
       "min         4.000000       0.000000       0.000000                 0.000000   \n",
       "25%         5.000000       1.000000       0.000000                 0.238071   \n",
       "50%         5.000000       4.000000       0.000000                 0.932579   \n",
       "75%         5.000000       5.000000       1.000000                 1.900338   \n",
       "max         5.000000       6.000000       1.000000              1915.000000   \n",
       "\n",
       "        has_hashtags   has_mentions       has_urls  number_of_urls  \\\n",
       "count  664949.000000  664949.000000  664949.000000   664949.000000   \n",
       "mean        0.108908       0.081600       0.321817        0.331013   \n",
       "std         0.311523       0.273755       0.467174        0.490283   \n",
       "min         0.000000       0.000000       0.000000        0.000000   \n",
       "25%         0.000000       0.000000       0.000000        0.000000   \n",
       "50%         0.000000       0.000000       0.000000        0.000000   \n",
       "75%         0.000000       0.000000       1.000000        1.000000   \n",
       "max         1.000000       1.000000       1.000000        5.000000   \n",
       "\n",
       "       number_of_mentions  number_of_hashtags  \n",
       "count       664949.000000       664949.000000  \n",
       "mean             0.129583            0.192349  \n",
       "std              0.559090            0.694441  \n",
       "min              0.000000            0.000000  \n",
       "25%              0.000000            0.000000  \n",
       "50%              0.000000            0.000000  \n",
       "75%              0.000000            0.000000  \n",
       "max             13.000000           18.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in train_data.columns:\n",
    "    train_data = train_data[ pd.to_numeric(train_data[col], errors='coerce').notnull() ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform to `numpy.array`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(train_data).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(665777, 22)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:, 1:]\n",
    "y = data[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y[y<100], bins=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y[(0<y)*(y<10)], bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y[(10<y)*(y<100)], bins=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Study of `y`: the retweet count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(665777,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "942572.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2972.0489492028046"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147.6873983330755"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the count of y == 0:  422803\n"
     ]
    }
   ],
   "source": [
    "print(\"the count of y == 0: \", (y==0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the count of y in ]0, 10]:  142546\n"
     ]
    }
   ],
   "source": [
    "print(\"the count of y in ]0, 10]: \", ((0 <  y) * (y < 10)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the count of y in ]10, 100]:  59400\n"
     ]
    }
   ],
   "source": [
    "print(\"the count of y in ]10, 100]: \", ((10 <  y) * (y < 100)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the count of y in ]100, inf]:  37163\n"
     ]
    }
   ],
   "source": [
    "print(\"the count of y in ]100, inf]: \", ((y > 100)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the count of y in ]1000, inf]:  10240\n"
     ]
    }
   ],
   "source": [
    "print(\"the count of y in ]1000, inf]: \", ((y > 1000)).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark\n",
    "\n",
    "- baseline: MAE ~ 280\n",
    "- all zero prediction: MAE ~ 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_zoo = {  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0 = (y > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242974"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y0.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Model: Classification, y = 0?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the histgram and statistic value above, we found that the nealy 2/3 of the tweet have 0 retweet, so we want to start by trying to classify if the tweet has retweet or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_0 = (y_train > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_1 = RandomForestClassifier(max_depth=20, random_state=42).fit(X_train, y_train_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.42011193e-02, 9.30361032e-03, 7.07755355e-02, 7.93885449e-03,\n",
       "       4.05201049e-03, 1.17956462e-03, 2.56440927e-04, 1.58138707e-03,\n",
       "       1.79875350e-03, 3.11093906e-02, 4.30955549e-02, 1.51360783e-02,\n",
       "       2.77151592e-01, 2.51995324e-01, 1.98968835e-02, 4.26249065e-02,\n",
       "       1.68936903e-01, 1.83957526e-02, 4.95158891e-03, 3.25376329e-03,\n",
       "       2.36498650e-03])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importance of features\n",
    "clf_1.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_zoo['base'] = clf_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = clf_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_0 = (y_test > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score:  0.9752035137343797\n",
      "accuracy:  0.9772973054162035\n"
     ]
    }
   ],
   "source": [
    "print( \"f1 score: \", f1_score(prediction, y_test_0, average=\"macro\") )\n",
    "print( \"accuracy: \", accuracy_score(prediction, y_test_0) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pick the threshold 0.03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Too slow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.03\n",
    "\n",
    "prediction = clf_1.predict_proba(X_test)\n",
    "y_pred_0 = (prediction[:,1] > threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[64588, 20101],\n",
       "       [  685, 47782]], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test_0, y_pred_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65273"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred_0.shape[0] - y_pred_0.sum()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentage of 0 predicted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4901994652888341"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred_0.shape[0] - y_pred_0.sum())  / y_pred_0.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141000.0\n",
      "8402.0\n",
      "1.0\n",
      "843.0\n",
      "1.0\n",
      "1.0\n",
      "36.0\n",
      "1.0\n",
      "18.0\n",
      "1.0\n",
      "7.0\n",
      "29.0\n",
      "2.0\n",
      "2.0\n",
      "4.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "12.0\n",
      "2406.0\n",
      "1.0\n",
      "2.0\n",
      "8.0\n",
      "2.0\n",
      "4.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1921.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "61.0\n",
      "1.0\n",
      "2.0\n",
      "8.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "45.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "5.0\n",
      "10014.0\n",
      "277.0\n",
      "5.0\n",
      "1.0\n",
      "1.0\n",
      "1106.0\n",
      "7.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "28.0\n",
      "2.0\n",
      "1.0\n",
      "16.0\n",
      "3.0\n",
      "1.0\n",
      "5.0\n",
      "2.0\n",
      "5.0\n",
      "1.0\n",
      "6.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "5.0\n",
      "11.0\n",
      "145.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "4.0\n",
      "1.0\n",
      "72.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "19.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "6.0\n",
      "1.0\n",
      "6.0\n",
      "10.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "69.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "272.0\n",
      "1.0\n",
      "6.0\n",
      "1.0\n",
      "10.0\n",
      "15.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "5.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "4.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "153.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "4.0\n",
      "3.0\n",
      "4.0\n",
      "567.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "558.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "2119.0\n",
      "6.0\n",
      "13.0\n",
      "391.0\n",
      "1.0\n",
      "19.0\n",
      "1.0\n",
      "1.0\n",
      "952.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "250.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "155.0\n",
      "31.0\n",
      "1.0\n",
      "4.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "15.0\n",
      "1.0\n",
      "5.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2413.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "781.0\n",
      "9.0\n",
      "11.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "516.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "7.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "13695.0\n",
      "1.0\n",
      "1.0\n",
      "190.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "175.0\n",
      "2.0\n",
      "14.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "2.0\n",
      "32218.0\n",
      "80.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "15.0\n",
      "2.0\n",
      "1.0\n",
      "13.0\n",
      "1.0\n",
      "129.0\n",
      "1.0\n",
      "2.0\n",
      "4.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "14903.0\n",
      "1.0\n",
      "5.0\n",
      "1.0\n",
      "1.0\n",
      "4.0\n",
      "1.0\n",
      "69.0\n",
      "6.0\n",
      "4.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "8.0\n",
      "25258.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "6.0\n",
      "11.0\n",
      "8.0\n",
      "36591.0\n",
      "8.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "17.0\n",
      "1.0\n",
      "10.0\n",
      "71.0\n",
      "4.0\n",
      "14.0\n",
      "1078.0\n",
      "1.0\n",
      "6.0\n",
      "1.0\n",
      "5.0\n",
      "1.0\n",
      "13.0\n",
      "2.0\n",
      "197.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "4.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "6.0\n",
      "4.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "4.0\n",
      "30.0\n",
      "1.0\n",
      "11.0\n",
      "10.0\n",
      "2.0\n",
      "1.0\n",
      "45.0\n",
      "6.0\n",
      "48.0\n",
      "2.0\n",
      "17.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "214.0\n",
      "1.0\n",
      "62.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "6.0\n",
      "3109.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "10.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "31984.0\n",
      "5.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "8.0\n",
      "6.0\n",
      "1.0\n",
      "2.0\n",
      "74.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "13171.0\n",
      "52.0\n",
      "1.0\n",
      "8.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "862.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "14.0\n",
      "1.0\n",
      "52.0\n",
      "1.0\n",
      "2.0\n",
      "600.0\n",
      "9.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "7.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "241.0\n",
      "1.0\n",
      "2.0\n",
      "710.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "6.0\n",
      "47.0\n",
      "2.0\n",
      "1.0\n",
      "46.0\n",
      "1.0\n",
      "85592.0\n",
      "1.0\n",
      "1.0\n",
      "6.0\n",
      "16.0\n",
      "1.0\n",
      "29.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "40.0\n",
      "1.0\n",
      "4.0\n",
      "2.0\n",
      "1.0\n",
      "6.0\n",
      "2002.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "535.0\n",
      "51.0\n",
      "11.0\n",
      "131.0\n",
      "1.0\n",
      "256.0\n",
      "7.0\n",
      "1988.0\n",
      "4.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "7.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "8.0\n",
      "11620.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "6.0\n",
      "1.0\n",
      "5.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "610.0\n",
      "1.0\n",
      "4.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "21.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "93.0\n",
      "43.0\n",
      "24.0\n",
      "2.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "20.0\n",
      "11.0\n",
      "2.0\n",
      "606.0\n",
      "1.0\n",
      "5.0\n",
      "4.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1682.0\n",
      "2.0\n",
      "1441.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "8949.0\n",
      "1.0\n",
      "1.0\n",
      "8813.0\n",
      "1.0\n",
      "1.0\n",
      "19280.0\n",
      "1498.0\n",
      "2.0\n",
      "3191.0\n",
      "1.0\n",
      "24.0\n",
      "3.0\n",
      "490.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "9.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "970.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "6.0\n",
      "43.0\n",
      "1.0\n",
      "6.0\n",
      "89.0\n",
      "8736.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "8768.0\n",
      "72.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "6.0\n",
      "2.0\n",
      "8.0\n",
      "60.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "29.0\n",
      "293.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "33.0\n",
      "1.0\n",
      "158.0\n",
      "1.0\n",
      "576.0\n",
      "1.0\n",
      "2.0\n",
      "8.0\n",
      "5.0\n",
      "1.0\n",
      "1.0\n",
      "1329.0\n",
      "1.0\n",
      "3213.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "167.0\n",
      "3.0\n",
      "6.0\n",
      "7.0\n",
      "360.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "19.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1550.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "11.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "6.0\n",
      "1.0\n",
      "1.0\n",
      "392.0\n",
      "3.0\n",
      "3.0\n",
      "8.0\n",
      "11.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "wrong = []\n",
    "for (pred, real) in zip(y_pred_0, y_test):\n",
    "    if pred == 0 and real > 0:\n",
    "        print(real)\n",
    "        wrong.append(real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong = np.array(wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(685,)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.103978674183812"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong.sum() / (y_pred_0.shape[0] - y_pred_0.sum()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Just MAE of 8.7 on 60\\% of data !**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the samples with classifier one `base` 's result being 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(532621, 21)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.03\n",
    "\n",
    "prediction = clf_1.predict_proba(X_train)\n",
    "mask = (prediction[:,1] > threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_1 = y_train[mask]\n",
    "X_train_1 = X_train[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(265509, 21)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298.1359426610774"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "942572.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_1.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second model: int( log(y) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classify the tweets by the order of the retweet count by int(log(y))\n",
    "\n",
    "- 0-10: 0\n",
    "- 11-100: 1\n",
    "- 101-1000: 2\n",
    "- 1001-10000: 3\n",
    "- 10001-100000: 4\n",
    "- 100001- $\\infty$: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_log = np.array(list(map( lambda x : int(np.log10(x)) if x > 0 else 0, y_train_1 )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.000e+00, 1.200e+01, 2.000e+00, ..., 0.000e+00, 4.854e+03,\n",
       "       2.000e+00])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 3, 0])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_log = np.array(list(map( lambda x : int(np.log10(x)) if x > 0 else 0, y_test )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_log.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45181519270533205"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_log.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of class 0 : 185174\n",
      "The number of class 1 : 50436\n",
      "The number of class 2 : 21697\n",
      "The number of class 3 : 6745\n",
      "The number of class 4 : 1389\n",
      "The number of class 5 : 68\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print( \"The number of class %d :\"%i, len(y_train_log[y_train_log == i]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a exponential trend in the distribution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need balanced training features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(i):\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    pos_count = 0\n",
    "    neg_count = 0\n",
    "    \n",
    "    while pos_count < 1000:\n",
    "        for x, y in zip(X_train_1, y_train_log):\n",
    "            if y > i:\n",
    "                X.append(x)\n",
    "                Y.append(1)\n",
    "                pos_count += 1\n",
    "            elif pos_count + 1 > neg_count * 0.8 and np.random.rand() > 0.5:\n",
    "                X.append(x)\n",
    "                Y.append(0)\n",
    "                neg_count += 1\n",
    "    print(\"positive_sample: \", pos_count, \"; negative sample: \", neg_count)\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = [22, 22, 20, 15, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive_sample:  80335 ; negative sample:  92624\n",
      "F1 in the test set: \n",
      " 0.6342464605847365\n",
      "ACC in the test set: \n",
      " 0.8688455646009192\n",
      "CM in the test set: \n",
      " [[100550   4941]\n",
      " [ 12523  15142]]\n",
      "positive_sample:  29899 ; negative sample:  37375\n",
      "F1 in the test set: \n",
      " 0.4377947885254774\n",
      "ACC in the test set: \n",
      " 0.8907897503679895\n",
      "CM in the test set: \n",
      " [[112952   1777]\n",
      " [ 12765   5662]]\n",
      "positive_sample:  8202 ; negative sample:  10254\n",
      "F1 in the test set: \n",
      " 0.12112167151048622\n",
      "ACC in the test set: \n",
      " 0.8319414821712878\n",
      "CM in the test set: \n",
      " [[109236    507]\n",
      " [ 21871   1542]]\n",
      "positive_sample:  1457 ; negative sample:  1823\n",
      "F1 in the test set: \n",
      " 0.014604128021670642\n",
      "ACC in the test set: \n",
      " 0.7486632220853735\n",
      "CM in the test set: \n",
      " [[99441   105]\n",
      " [33362   248]]\n",
      "positive_sample:  1020 ; negative sample:  1277\n",
      "F1 in the test set: \n",
      " 0.0006824191759788451\n",
      "ACC in the test set: \n",
      " 0.9120204872480399\n",
      "CM in the test set: \n",
      " [[121437     15]\n",
      " [ 11700      4]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    X_train, y_train = get_train_data(i)\n",
    "    clf = RandomForestClassifier(max_depth=max_depth[i], random_state=42).fit(X_train, y_train)\n",
    "    clf_zoo[i] = clf \n",
    "    y_test_ = (y_test_log > i)\n",
    "    \n",
    "    print( \"F1 in the test set: \\n\", f1_score( clf.predict(X_test), y_test_))\n",
    "    print( \"ACC in the test set: \\n\", accuracy_score( clf.predict(X_test), y_test_))\n",
    "    print( \"CM in the test set: \\n\", confusion_matrix( clf.predict(X_test), y_test_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes_pos(x):\n",
    "    res = np.zeros(6)\n",
    "    p0 = clf_zoo['base'].predict_proba([x])[0,1]\n",
    "    if p0 < 0.03:\n",
    "        res[0] = 1\n",
    "        return res\n",
    "    for i in range(5):\n",
    "        res[i+1] = clf_zoo[i].predict_proba([x])[0,1]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.16414018, 0.1817707 , 0.06142857, 0.18157475,\n",
       "       0.14      ])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classes_pos(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.96173993 0.57630779 0.28409503 0.6353251  0.07      ]\n",
      "95.0\n"
     ]
    }
   ],
   "source": [
    "print(get_classes_pos(X_test[3]))\n",
    "print(y_test[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_classfication(X_val, y_val, threshold, average):\n",
    "    y_predict = np.zeros(y_val.shape[0])\n",
    "    \n",
    "    \n",
    "    for (i, x) in enumerate(X_val):\n",
    "        if (i % 2000 == 0):\n",
    "            print(\"processed: \", i)\n",
    "        p = get_classes_pos(x)\n",
    "        if p[0] > 0:\n",
    "            y_predict[i] = 0\n",
    "        else:\n",
    "            largest_class = 0\n",
    "            for j in range(5):\n",
    "                if p[j+1] >= threshold[j]:\n",
    "                    largest_class = j+1\n",
    "            y_predict[i] = 10**largest_class * average\n",
    "\n",
    "    cost = np.abs(y_val - y_predict).mean()\n",
    "    print(\"cost at \", threshold, \": \", cost)\n",
    "    return cost, y_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = [0.47092152, 0.55543368, 1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_threshold = [0.47092152, 0.55543368, 0.868192  , 0.76829936, 0.97466098]\n",
    "optimal_cost = 142"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_test[10000:20000]\n",
    "y_val = y_test[10000:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed:  0\n",
      "processed:  2000\n",
      "processed:  4000\n",
      "processed:  6000\n",
      "processed:  8000\n",
      "cost at  [0.47092152, 0.55543368, 1, 1, 1] :  147.88996\n"
     ]
    }
   ],
   "source": [
    "y_predict = validate_classfication(X_val, y_val, threshold, 0.3)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4064399999999995"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149.2856"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed:  0\n",
      "processed:  2000\n",
      "processed:  4000\n",
      "processed:  6000\n",
      "processed:  8000\n",
      "cost at  [0.47       0.5        0.75483704 0.62013479 0.69677265] :  142.16107\n",
      "processed:  0\n",
      "processed:  2000\n",
      "processed:  4000\n",
      "processed:  6000\n",
      "processed:  8000\n",
      "cost at  [0.47       0.5        0.53580803 0.73569267 0.6076013 ] :  149.78367999999998\n",
      "processed:  0\n",
      "processed:  2000\n",
      "processed:  4000\n",
      "processed:  6000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-f9b8fb0f9607>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#     threshold = optimal_threshold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_classfication\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcost\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0moptimal_cost\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-77-682355dac40c>\u001b[0m in \u001b[0;36mvalidate_classfication\u001b[1;34m(X_val, y_val, threshold, average)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"processed: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_classes_pos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0my_predict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-60-9c819923a597>\u001b[0m in \u001b[0;36mget_classes_pos\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_zoo\u001b[0m\u001b[1;33m[\u001b[0m \u001b[1;34m\">10**%d\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    667\u001b[0m             delayed(_accumulate_prediction)(e.predict_proba, X, all_proba,\n\u001b[0;32m    668\u001b[0m                                             lock)\n\u001b[1;32m--> 669\u001b[1;33m             for e in self.estimators_)\n\u001b[0m\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mproba\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_proba\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    833\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_accumulate_prediction\u001b[1;34m(predict, X, out, lock)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[0mcomplains\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mit\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mpickle\u001b[0m \u001b[0mit\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mplaced\u001b[0m \u001b[0mthere\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m     \"\"\"\n\u001b[1;32m--> 449\u001b[1;33m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mlock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    904\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    905\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 906\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    907\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "experience_count = 0\n",
    "while(experience_count < 20):\n",
    "    threshold = np.array([0.47, 0.5, 0.5, 0.6, 0.6]) + \\\n",
    "                            np.array( [0 * np.random.rand(), 0 * np.random.rand(), 0.4 * np.random.rand(), 0.2 * np.random.rand(), 0.1 * np.random.rand() ])\n",
    "    y_predict = np.zeros(y_val.shape[0])\n",
    "#     threshold = optimal_threshold\n",
    "    \n",
    "    cost = validate_classfication(X_val, y_val, threshold, 0.3)[0]\n",
    "    \n",
    "    if cost < optimal_cost:\n",
    "        optimal_cost = cost\n",
    "        optimal_threshold = threshold\n",
    "        optimal_y_predict = y_predict\n",
    "    experience_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimal threshold value: [0.47092152, 0.55543368, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47092152, 0.55543368, 0.868192  , 0.76829936, 0.97466098])"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185.0507"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(y_predict[:10000] - y_test[:10000]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = y_predict[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4064399999999995"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.3, 30. ,  0. ,  0. ,  0.3, 30. ,  0.3, 30. ,  0.3,  0.3,  0.3,\n",
       "        0.3,  0. ,  0.3, 30. ,  0. ,  0.3,  0.3,  0. ,  0.3,  0. , 30. ,\n",
       "        0. ,  0. ,  0.3,  0.3,  0.3,  0. ,  3. ,  0. ,  0.3,  0. ,  0. ,\n",
       "        0. ,  0. ,  0.3,  0.3, 30. , 30. ,  0. ,  0.3,  0. ,  3. ,  3. ,\n",
       "        0. ,  0. ,  0.3,  0. ,  0. ,  3. , 30. , 30. ,  0. , 30. ,  0. ,\n",
       "        0.3, 30. ,  0. ,  0. ,  0. , 30. ,  0. ,  0. ,  0. ,  0.3,  0. ,\n",
       "        3. ,  0. ,  0.3,  0.3,  0. , 30. , 30. ,  0.3,  3. ,  0.3,  0. ,\n",
       "        0. ,  0.3,  0. ,  0.3,  3. ,  3. ,  0. ,  3. ,  0. ,  0.3,  0.3,\n",
       "        0.3,  0. ,  0. ,  3. ,  3. ,  0. ,  0. ,  0. ,  0. ,  0. , 30. ,\n",
       "        0. ])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 5.0000e+00,\n",
       "       8.8000e+01, 5.0000e+00, 5.2000e+01, 1.0000e+00, 0.0000e+00,\n",
       "       1.0000e+00, 4.0000e+00, 0.0000e+00, 0.0000e+00, 4.0800e+02,\n",
       "       0.0000e+00, 6.0000e+00, 2.6000e+02, 0.0000e+00, 1.0000e+00,\n",
       "       0.0000e+00, 6.7261e+04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 1.0000e+00, 0.0000e+00, 2.9000e+01, 0.0000e+00,\n",
       "       5.4000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 1.0600e+02, 1.0000e+00, 0.0000e+00,\n",
       "       2.0000e+00, 5.0000e+00, 3.2800e+02, 3.5200e+02, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5000e+01,\n",
       "       2.4600e+02, 1.0000e+00, 0.0000e+00, 7.0000e+01, 0.0000e+00,\n",
       "       2.0000e+00, 2.8000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       4.0950e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 1.0000e+01, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "       0.0000e+00, 1.0000e+00, 2.0000e+00, 1.0000e+00, 7.0000e+00,\n",
       "       4.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 1.0000e+01, 1.7000e+01, 0.0000e+00, 1.3000e+01,\n",
       "       0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 1.0000e+00, 6.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4000e+01, 0.0000e+00])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_clf():\n",
    "    \n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=1e-2,\n",
    "        decay_steps=100000,\n",
    "        decay_rate=0.99)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[tf.metrics.binary_accuracy])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive_sample:  1040 ; negative sample:  1302\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_data(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1873 samples, validate on 469 samples\n",
      "Epoch 1/30\n",
      "1873/1873 [==============================] - 1s 512us/sample - loss: 1.6230 - binary_accuracy: 0.5547 - val_loss: 0.6981 - val_binary_accuracy: 0.4435\n",
      "Epoch 2/30\n",
      "1873/1873 [==============================] - 0s 12us/sample - loss: 0.6950 - binary_accuracy: 0.4495 - val_loss: 0.6866 - val_binary_accuracy: 0.5565\n",
      "Epoch 3/30\n",
      "1873/1873 [==============================] - 0s 13us/sample - loss: 0.6751 - binary_accuracy: 0.5558 - val_loss: 1.0056 - val_binary_accuracy: 0.5565\n",
      "Epoch 4/30\n",
      "1873/1873 [==============================] - 0s 13us/sample - loss: 0.6390 - binary_accuracy: 0.6337 - val_loss: 2.1474 - val_binary_accuracy: 0.5565\n",
      "Epoch 5/30\n",
      "1873/1873 [==============================] - 0s 13us/sample - loss: 0.6057 - binary_accuracy: 0.6733 - val_loss: 0.7008 - val_binary_accuracy: 0.6098\n",
      "Epoch 6/30\n",
      "1873/1873 [==============================] - 0s 12us/sample - loss: 0.5477 - binary_accuracy: 0.7256 - val_loss: 1.6257 - val_binary_accuracy: 0.5778\n",
      "Epoch 7/30\n",
      "1873/1873 [==============================] - 0s 13us/sample - loss: 0.4990 - binary_accuracy: 0.7411 - val_loss: 2.0425 - val_binary_accuracy: 0.5906\n",
      "Epoch 8/30\n",
      "1873/1873 [==============================] - 0s 13us/sample - loss: 0.4601 - binary_accuracy: 0.7528 - val_loss: 1.3814 - val_binary_accuracy: 0.5970\n",
      "Epoch 9/30\n",
      "1873/1873 [==============================] - 0s 12us/sample - loss: 0.4364 - binary_accuracy: 0.7816 - val_loss: 2.1312 - val_binary_accuracy: 0.5970\n",
      "Epoch 10/30\n",
      "1873/1873 [==============================] - 0s 14us/sample - loss: 0.4024 - binary_accuracy: 0.7822 - val_loss: 2.7545 - val_binary_accuracy: 0.6055\n",
      "Epoch 11/30\n",
      "1873/1873 [==============================] - 0s 13us/sample - loss: 0.3757 - binary_accuracy: 0.8057 - val_loss: 3.1540 - val_binary_accuracy: 0.6098\n",
      "Epoch 12/30\n",
      "1873/1873 [==============================] - 0s 13us/sample - loss: 0.3695 - binary_accuracy: 0.8174 - val_loss: 2.8128 - val_binary_accuracy: 0.6034\n",
      "Epoch 13/30\n",
      "1873/1873 [==============================] - 0s 13us/sample - loss: 0.3397 - binary_accuracy: 0.8409 - val_loss: 3.8369 - val_binary_accuracy: 0.6269\n",
      "Epoch 14/30\n",
      "1873/1873 [==============================] - 0s 12us/sample - loss: 0.3157 - binary_accuracy: 0.8452 - val_loss: 3.4282 - val_binary_accuracy: 0.6588\n",
      "Epoch 15/30\n",
      "1873/1873 [==============================] - 0s 14us/sample - loss: 0.3563 - binary_accuracy: 0.8350 - val_loss: 3.7161 - val_binary_accuracy: 0.6290\n",
      "Epoch 16/30\n",
      "1873/1873 [==============================] - 0s 13us/sample - loss: 0.3165 - binary_accuracy: 0.8393 - val_loss: 2.6589 - val_binary_accuracy: 0.6397\n",
      "Epoch 17/30\n",
      "1873/1873 [==============================] - 0s 13us/sample - loss: 0.3096 - binary_accuracy: 0.8655 - val_loss: 2.4010 - val_binary_accuracy: 0.6695\n",
      "Epoch 18/30\n",
      "1873/1873 [==============================] - 0s 12us/sample - loss: 0.3017 - binary_accuracy: 0.8558 - val_loss: 2.0443 - val_binary_accuracy: 0.7356\n",
      "Epoch 19/30\n",
      "1873/1873 [==============================] - 0s 13us/sample - loss: 0.2878 - binary_accuracy: 0.8649 - val_loss: 2.7588 - val_binary_accuracy: 0.7164\n",
      "Epoch 20/30\n",
      "1873/1873 [==============================] - 0s 13us/sample - loss: 0.2691 - binary_accuracy: 0.8660 - val_loss: 3.2247 - val_binary_accuracy: 0.7100\n",
      "Epoch 21/30\n",
      "1873/1873 [==============================] - 0s 12us/sample - loss: 0.2757 - binary_accuracy: 0.8660 - val_loss: 2.5220 - val_binary_accuracy: 0.7292\n",
      "Epoch 22/30\n",
      "1873/1873 [==============================] - 0s 13us/sample - loss: 0.2867 - binary_accuracy: 0.8553 - val_loss: 1.6997 - val_binary_accuracy: 0.7335\n",
      "Epoch 23/30\n",
      "1873/1873 [==============================] - 0s 13us/sample - loss: 0.2675 - binary_accuracy: 0.8767 - val_loss: 2.3719 - val_binary_accuracy: 0.7271\n",
      "Epoch 24/30\n",
      "1873/1873 [==============================] - 0s 12us/sample - loss: 0.2799 - binary_accuracy: 0.8644 - val_loss: 1.5139 - val_binary_accuracy: 0.7569\n",
      "Epoch 25/30\n",
      "1873/1873 [==============================] - 0s 13us/sample - loss: 0.2803 - binary_accuracy: 0.8585 - val_loss: 1.5780 - val_binary_accuracy: 0.7633\n",
      "Epoch 26/30\n",
      "1873/1873 [==============================] - 0s 14us/sample - loss: 0.3050 - binary_accuracy: 0.8607 - val_loss: 1.3075 - val_binary_accuracy: 0.7612\n",
      "Epoch 27/30\n",
      "1873/1873 [==============================] - 0s 12us/sample - loss: 0.2704 - binary_accuracy: 0.8628 - val_loss: 1.2198 - val_binary_accuracy: 0.7569\n",
      "Epoch 28/30\n",
      "1873/1873 [==============================] - 0s 12us/sample - loss: 0.2686 - binary_accuracy: 0.8740 - val_loss: 1.1143 - val_binary_accuracy: 0.7484\n",
      "Epoch 29/30\n",
      "1873/1873 [==============================] - 0s 12us/sample - loss: 0.2556 - binary_accuracy: 0.8825 - val_loss: 1.1919 - val_binary_accuracy: 0.7548\n",
      "Epoch 30/30\n",
      "1873/1873 [==============================] - 0s 12us/sample - loss: 0.2520 - binary_accuracy: 0.9018 - val_loss: 1.2858 - val_binary_accuracy: 0.7527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21258797550>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 30\n",
    "batch_size = 1024\n",
    "model_clf = build_model_clf()\n",
    "model_clf.fit(X_train, y_train, epochs=epochs, batch_size = batch_size, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive_sample:  79837 ; negative sample:  99760\n",
      "Train on 143677 samples, validate on 35920 samples\n",
      "Epoch 1/30\n",
      "143677/143677 [==============================] - 2s 16us/sample - loss: 0.5132 - binary_accuracy: 0.7439 - val_loss: 0.5085 - val_binary_accuracy: 0.7482\n",
      "Epoch 2/30\n",
      "143677/143677 [==============================] - 1s 9us/sample - loss: 0.4861 - binary_accuracy: 0.7601 - val_loss: 0.4725 - val_binary_accuracy: 0.7692\n",
      "Epoch 3/30\n",
      "143677/143677 [==============================] - 1s 9us/sample - loss: 0.4848 - binary_accuracy: 0.7613 - val_loss: 0.4737 - val_binary_accuracy: 0.7649\n",
      "Epoch 4/30\n",
      "143677/143677 [==============================] - 1s 9us/sample - loss: 0.4782 - binary_accuracy: 0.7636 - val_loss: 0.4721 - val_binary_accuracy: 0.7698\n",
      "Epoch 5/30\n",
      "143677/143677 [==============================] - 1s 9us/sample - loss: 0.4784 - binary_accuracy: 0.7626 - val_loss: 0.4690 - val_binary_accuracy: 0.7708\n",
      "Epoch 6/30\n",
      "143677/143677 [==============================] - 1s 9us/sample - loss: 0.4782 - binary_accuracy: 0.7641 - val_loss: 0.4737 - val_binary_accuracy: 0.7692\n",
      "Epoch 7/30\n",
      "143677/143677 [==============================] - 1s 9us/sample - loss: 0.4770 - binary_accuracy: 0.7647 - val_loss: 0.4706 - val_binary_accuracy: 0.7675\n",
      "Epoch 8/30\n",
      "143677/143677 [==============================] - 1s 9us/sample - loss: 0.4763 - binary_accuracy: 0.7655 - val_loss: 0.4733 - val_binary_accuracy: 0.7682\n",
      "Epoch 9/30\n",
      "143677/143677 [==============================] - 1s 9us/sample - loss: 0.4744 - binary_accuracy: 0.7662 - val_loss: 0.4661 - val_binary_accuracy: 0.7725\n",
      "Epoch 10/30\n",
      "143677/143677 [==============================] - 1s 9us/sample - loss: 0.4751 - binary_accuracy: 0.7658 - val_loss: 0.4746 - val_binary_accuracy: 0.7599\n",
      "Epoch 11/30\n",
      "143677/143677 [==============================] - 1s 9us/sample - loss: 0.4726 - binary_accuracy: 0.7660 - val_loss: 0.4750 - val_binary_accuracy: 0.7679\n",
      "Epoch 12/30\n",
      "143677/143677 [==============================] - 1s 9us/sample - loss: 0.4716 - binary_accuracy: 0.7664 - val_loss: 0.4678 - val_binary_accuracy: 0.7682\n",
      "Epoch 13/30\n",
      "143677/143677 [==============================] - 1s 9us/sample - loss: 0.4730 - binary_accuracy: 0.7652 - val_loss: 0.4649 - val_binary_accuracy: 0.7732\n",
      "Epoch 14/30\n",
      "143677/143677 [==============================] - 1s 9us/sample - loss: 0.4715 - binary_accuracy: 0.7666 - val_loss: 0.4678 - val_binary_accuracy: 0.7698\n",
      "Epoch 15/30\n",
      "143677/143677 [==============================] - 1s 9us/sample - loss: 0.4714 - binary_accuracy: 0.7673 - val_loss: 0.4646 - val_binary_accuracy: 0.7714\n",
      "Epoch 16/30\n",
      "143677/143677 [==============================] - 1s 9us/sample - loss: 0.4726 - binary_accuracy: 0.7662 - val_loss: 0.4739 - val_binary_accuracy: 0.7693\n",
      "Epoch 17/30\n",
      "143677/143677 [==============================] - 1s 9us/sample - loss: 0.4714 - binary_accuracy: 0.7660 - val_loss: 0.4636 - val_binary_accuracy: 0.7731\n",
      "Epoch 18/30\n",
      "143677/143677 [==============================] - 1s 9us/sample - loss: 0.4692 - binary_accuracy: 0.7677 - val_loss: 0.4654 - val_binary_accuracy: 0.7727\n",
      "Epoch 19/30\n",
      "143677/143677 [==============================] - 1s 9us/sample - loss: 0.4700 - binary_accuracy: 0.7675 - val_loss: 0.4676 - val_binary_accuracy: 0.7716\n",
      "Epoch 20/30\n",
      "143677/143677 [==============================] - 1s 9us/sample - loss: 0.4694 - binary_accuracy: 0.7676 - val_loss: 0.4662 - val_binary_accuracy: 0.7709\n",
      "Epoch 21/30\n",
      "143677/143677 [==============================] - 1s 9us/sample - loss: 0.4687 - binary_accuracy: 0.7678 - val_loss: 0.4663 - val_binary_accuracy: 0.7711\n",
      "Epoch 22/30\n",
      "143677/143677 [==============================] - 1s 9us/sample - loss: 0.4681 - binary_accuracy: 0.7694 - val_loss: 0.4616 - val_binary_accuracy: 0.7726\n",
      "Epoch 23/30\n",
      "143677/143677 [==============================] - 1s 9us/sample - loss: 0.4700 - binary_accuracy: 0.7672 - val_loss: 0.4695 - val_binary_accuracy: 0.7639\n",
      "Epoch 24/30\n",
      "143677/143677 [==============================] - 1s 9us/sample - loss: 0.4696 - binary_accuracy: 0.7673 - val_loss: 0.4752 - val_binary_accuracy: 0.7644\n",
      "Epoch 25/30\n",
      "143677/143677 [==============================] - 1s 9us/sample - loss: 0.4707 - binary_accuracy: 0.7671 - val_loss: 0.4659 - val_binary_accuracy: 0.7683\n",
      "Epoch 26/30\n",
      "143677/143677 [==============================] - 1s 9us/sample - loss: 0.4680 - binary_accuracy: 0.7682 - val_loss: 0.4605 - val_binary_accuracy: 0.7746\n",
      "Epoch 27/30\n",
      "143677/143677 [==============================] - 1s 9us/sample - loss: 0.4677 - binary_accuracy: 0.7687 - val_loss: 0.4610 - val_binary_accuracy: 0.7747\n",
      "Epoch 28/30\n",
      "143677/143677 [==============================] - 1s 9us/sample - loss: 0.4679 - binary_accuracy: 0.7687 - val_loss: 0.4618 - val_binary_accuracy: 0.7747\n",
      "Epoch 29/30\n",
      "143677/143677 [==============================] - 1s 9us/sample - loss: 0.4676 - binary_accuracy: 0.7704 - val_loss: 0.4627 - val_binary_accuracy: 0.7729\n",
      "Epoch 30/30\n",
      "143677/143677 [==============================] - 1s 9us/sample - loss: 0.4694 - binary_accuracy: 0.7677 - val_loss: 0.4646 - val_binary_accuracy: 0.7705\n",
      "F1 in the test set: \n",
      " 0.28159340659340665\n",
      "ACC in the test set: \n",
      " 0.8348296864425897\n",
      "CM in the test set: \n",
      " [[106719  15779]\n",
      " [  6187   4305]]\n",
      "positive_sample:  29550 ; negative sample:  36938\n",
      "Train on 53190 samples, validate on 13298 samples\n",
      "Epoch 1/30\n",
      "53190/53190 [==============================] - 1s 26us/sample - loss: 0.5681 - binary_accuracy: 0.7257 - val_loss: 0.6700 - val_binary_accuracy: 0.5957\n",
      "Epoch 2/30\n",
      "53190/53190 [==============================] - 0s 9us/sample - loss: 0.5092 - binary_accuracy: 0.7511 - val_loss: 0.5106 - val_binary_accuracy: 0.7500\n",
      "Epoch 3/30\n",
      "53190/53190 [==============================] - 0s 9us/sample - loss: 0.4994 - binary_accuracy: 0.7579 - val_loss: 0.5262 - val_binary_accuracy: 0.7177\n",
      "Epoch 4/30\n",
      "53190/53190 [==============================] - 0s 9us/sample - loss: 0.4927 - binary_accuracy: 0.7593 - val_loss: 0.5157 - val_binary_accuracy: 0.7570\n",
      "Epoch 5/30\n",
      "53190/53190 [==============================] - 0s 9us/sample - loss: 0.4935 - binary_accuracy: 0.7606 - val_loss: 0.4880 - val_binary_accuracy: 0.7698\n",
      "Epoch 6/30\n",
      "53190/53190 [==============================] - 0s 9us/sample - loss: 0.4858 - binary_accuracy: 0.7636 - val_loss: 0.4719 - val_binary_accuracy: 0.7777\n",
      "Epoch 7/30\n",
      "53190/53190 [==============================] - 0s 9us/sample - loss: 0.4864 - binary_accuracy: 0.7662 - val_loss: 0.4766 - val_binary_accuracy: 0.7731\n",
      "Epoch 8/30\n",
      "53190/53190 [==============================] - 0s 9us/sample - loss: 0.4904 - binary_accuracy: 0.7652 - val_loss: 0.4798 - val_binary_accuracy: 0.7760\n",
      "Epoch 9/30\n",
      "53190/53190 [==============================] - 0s 9us/sample - loss: 0.4877 - binary_accuracy: 0.7627 - val_loss: 0.4777 - val_binary_accuracy: 0.7730\n",
      "Epoch 10/30\n",
      "53190/53190 [==============================] - 0s 9us/sample - loss: 0.4782 - binary_accuracy: 0.7672 - val_loss: 0.4781 - val_binary_accuracy: 0.7749\n",
      "Epoch 11/30\n",
      "53190/53190 [==============================] - 0s 9us/sample - loss: 0.4813 - binary_accuracy: 0.7677 - val_loss: 0.4742 - val_binary_accuracy: 0.7671\n",
      "Epoch 12/30\n",
      "53190/53190 [==============================] - 0s 9us/sample - loss: 0.4833 - binary_accuracy: 0.7649 - val_loss: 0.5166 - val_binary_accuracy: 0.7624\n",
      "Epoch 13/30\n",
      "53190/53190 [==============================] - 0s 9us/sample - loss: 0.4792 - binary_accuracy: 0.7688 - val_loss: 0.4662 - val_binary_accuracy: 0.7739\n",
      "Epoch 14/30\n",
      "53190/53190 [==============================] - 0s 9us/sample - loss: 0.4783 - binary_accuracy: 0.7698 - val_loss: 0.4764 - val_binary_accuracy: 0.7748\n",
      "Epoch 15/30\n",
      "53190/53190 [==============================] - 0s 9us/sample - loss: 0.4788 - binary_accuracy: 0.7670 - val_loss: 0.4617 - val_binary_accuracy: 0.7796\n",
      "Epoch 16/30\n",
      "53190/53190 [==============================] - 0s 9us/sample - loss: 0.4788 - binary_accuracy: 0.7688 - val_loss: 0.4690 - val_binary_accuracy: 0.7710\n",
      "Epoch 17/30\n",
      "53190/53190 [==============================] - 0s 9us/sample - loss: 0.4766 - binary_accuracy: 0.7706 - val_loss: 0.4659 - val_binary_accuracy: 0.7779\n",
      "Epoch 18/30\n",
      "53190/53190 [==============================] - 0s 9us/sample - loss: 0.4735 - binary_accuracy: 0.7718 - val_loss: 0.4650 - val_binary_accuracy: 0.7709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "53190/53190 [==============================] - 0s 9us/sample - loss: 0.4762 - binary_accuracy: 0.7685 - val_loss: 0.4642 - val_binary_accuracy: 0.7770\n",
      "Epoch 20/30\n",
      "53190/53190 [==============================] - 1s 9us/sample - loss: 0.4750 - binary_accuracy: 0.7705 - val_loss: 0.4749 - val_binary_accuracy: 0.7627\n",
      "Epoch 21/30\n",
      "53190/53190 [==============================] - 0s 9us/sample - loss: 0.4759 - binary_accuracy: 0.7681 - val_loss: 0.4856 - val_binary_accuracy: 0.7736\n",
      "Epoch 22/30\n",
      "53190/53190 [==============================] - 0s 9us/sample - loss: 0.4799 - binary_accuracy: 0.7676 - val_loss: 0.4683 - val_binary_accuracy: 0.7752\n",
      "Epoch 23/30\n",
      "53190/53190 [==============================] - 0s 9us/sample - loss: 0.4733 - binary_accuracy: 0.7705 - val_loss: 0.4643 - val_binary_accuracy: 0.7757\n",
      "Epoch 24/30\n",
      "53190/53190 [==============================] - 0s 9us/sample - loss: 0.4705 - binary_accuracy: 0.7743 - val_loss: 0.4692 - val_binary_accuracy: 0.7753\n",
      "Epoch 25/30\n",
      "53190/53190 [==============================] - 0s 9us/sample - loss: 0.4705 - binary_accuracy: 0.7723 - val_loss: 0.4704 - val_binary_accuracy: 0.7708\n",
      "Epoch 26/30\n",
      "53190/53190 [==============================] - 0s 9us/sample - loss: 0.4718 - binary_accuracy: 0.7718 - val_loss: 0.4735 - val_binary_accuracy: 0.7704\n",
      "Epoch 27/30\n",
      "53190/53190 [==============================] - 0s 9us/sample - loss: 0.4706 - binary_accuracy: 0.7744 - val_loss: 0.4636 - val_binary_accuracy: 0.7768\n",
      "Epoch 28/30\n",
      "53190/53190 [==============================] - 0s 9us/sample - loss: 0.4693 - binary_accuracy: 0.7726 - val_loss: 0.4647 - val_binary_accuracy: 0.7748\n",
      "Epoch 29/30\n",
      "53190/53190 [==============================] - 0s 9us/sample - loss: 0.4717 - binary_accuracy: 0.7726 - val_loss: 0.4712 - val_binary_accuracy: 0.7736\n",
      "Epoch 30/30\n",
      "53190/53190 [==============================] - 0s 9us/sample - loss: 0.4759 - binary_accuracy: 0.7708 - val_loss: 0.4646 - val_binary_accuracy: 0.7710\n",
      "F1 in the test set: \n",
      " 0.2606477373558119\n",
      "ACC in the test set: \n",
      " 0.8997518610421836\n",
      "CM in the test set: \n",
      " [[117308   5190]\n",
      " [  8142   2350]]\n",
      "positive_sample:  8114 ; negative sample:  10144\n",
      "Train on 14606 samples, validate on 3652 samples\n",
      "Epoch 1/30\n",
      "14606/14606 [==============================] - 1s 71us/sample - loss: 0.7705 - binary_accuracy: 0.6670 - val_loss: 0.6627 - val_binary_accuracy: 0.6914\n",
      "Epoch 2/30\n",
      "14606/14606 [==============================] - 0s 10us/sample - loss: 0.5116 - binary_accuracy: 0.7499 - val_loss: 0.5717 - val_binary_accuracy: 0.7084\n",
      "Epoch 3/30\n",
      "14606/14606 [==============================] - 0s 10us/sample - loss: 0.4916 - binary_accuracy: 0.7585 - val_loss: 0.5369 - val_binary_accuracy: 0.7234\n",
      "Epoch 4/30\n",
      "14606/14606 [==============================] - 0s 10us/sample - loss: 0.4856 - binary_accuracy: 0.7588 - val_loss: 0.5581 - val_binary_accuracy: 0.7223\n",
      "Epoch 5/30\n",
      "14606/14606 [==============================] - 0s 10us/sample - loss: 0.4831 - binary_accuracy: 0.7628 - val_loss: 0.5148 - val_binary_accuracy: 0.7390\n",
      "Epoch 6/30\n",
      "14606/14606 [==============================] - 0s 10us/sample - loss: 0.4871 - binary_accuracy: 0.7627 - val_loss: 0.5299 - val_binary_accuracy: 0.7327\n",
      "Epoch 7/30\n",
      "14606/14606 [==============================] - 0s 10us/sample - loss: 0.4735 - binary_accuracy: 0.7641 - val_loss: 0.5143 - val_binary_accuracy: 0.7341\n",
      "Epoch 8/30\n",
      "14606/14606 [==============================] - 0s 10us/sample - loss: 0.4838 - binary_accuracy: 0.7669 - val_loss: 0.5393 - val_binary_accuracy: 0.7106\n",
      "Epoch 9/30\n",
      "14606/14606 [==============================] - 0s 10us/sample - loss: 0.4693 - binary_accuracy: 0.7723 - val_loss: 0.5110 - val_binary_accuracy: 0.7467\n",
      "Epoch 10/30\n",
      "14606/14606 [==============================] - 0s 10us/sample - loss: 0.4679 - binary_accuracy: 0.7694 - val_loss: 0.4929 - val_binary_accuracy: 0.7577\n",
      "Epoch 11/30\n",
      "14606/14606 [==============================] - 0s 10us/sample - loss: 0.4799 - binary_accuracy: 0.7624 - val_loss: 0.4867 - val_binary_accuracy: 0.7694\n",
      "Epoch 12/30\n",
      "14606/14606 [==============================] - 0s 10us/sample - loss: 0.4813 - binary_accuracy: 0.7719 - val_loss: 0.5121 - val_binary_accuracy: 0.7500\n",
      "Epoch 13/30\n",
      "14606/14606 [==============================] - 0s 10us/sample - loss: 0.4685 - binary_accuracy: 0.7700 - val_loss: 0.4950 - val_binary_accuracy: 0.7585\n",
      "Epoch 14/30\n",
      "14606/14606 [==============================] - 0s 10us/sample - loss: 0.4754 - binary_accuracy: 0.7727 - val_loss: 0.4734 - val_binary_accuracy: 0.7620\n",
      "Epoch 15/30\n",
      "14606/14606 [==============================] - 0s 10us/sample - loss: 0.4674 - binary_accuracy: 0.7704 - val_loss: 0.4844 - val_binary_accuracy: 0.7601\n",
      "Epoch 16/30\n",
      "14606/14606 [==============================] - 0s 10us/sample - loss: 0.4655 - binary_accuracy: 0.7741 - val_loss: 0.4784 - val_binary_accuracy: 0.7673\n",
      "Epoch 17/30\n",
      "14606/14606 [==============================] - 0s 10us/sample - loss: 0.4669 - binary_accuracy: 0.7757 - val_loss: 0.4724 - val_binary_accuracy: 0.7634\n",
      "Epoch 18/30\n",
      "14606/14606 [==============================] - 0s 10us/sample - loss: 0.4679 - binary_accuracy: 0.7715 - val_loss: 0.4870 - val_binary_accuracy: 0.7681\n",
      "Epoch 19/30\n",
      "14606/14606 [==============================] - 0s 10us/sample - loss: 0.4659 - binary_accuracy: 0.7739 - val_loss: 0.4819 - val_binary_accuracy: 0.7508\n",
      "Epoch 20/30\n",
      "14606/14606 [==============================] - 0s 10us/sample - loss: 0.4654 - binary_accuracy: 0.7739 - val_loss: 0.4753 - val_binary_accuracy: 0.7675\n",
      "Epoch 21/30\n",
      "14606/14606 [==============================] - 0s 10us/sample - loss: 0.4687 - binary_accuracy: 0.7773 - val_loss: 0.5010 - val_binary_accuracy: 0.7577\n",
      "Epoch 22/30\n",
      "14606/14606 [==============================] - 0s 10us/sample - loss: 0.4741 - binary_accuracy: 0.7695 - val_loss: 0.4834 - val_binary_accuracy: 0.7659\n",
      "Epoch 23/30\n",
      "14606/14606 [==============================] - 0s 10us/sample - loss: 0.4565 - binary_accuracy: 0.7828 - val_loss: 0.4772 - val_binary_accuracy: 0.7741\n",
      "Epoch 24/30\n",
      "14606/14606 [==============================] - 0s 10us/sample - loss: 0.4631 - binary_accuracy: 0.7761 - val_loss: 0.4812 - val_binary_accuracy: 0.7752\n",
      "Epoch 25/30\n",
      "14606/14606 [==============================] - 0s 10us/sample - loss: 0.4734 - binary_accuracy: 0.7729 - val_loss: 0.4779 - val_binary_accuracy: 0.7656\n",
      "Epoch 26/30\n",
      "14606/14606 [==============================] - 0s 10us/sample - loss: 0.4590 - binary_accuracy: 0.7794 - val_loss: 0.4723 - val_binary_accuracy: 0.7634\n",
      "Epoch 27/30\n",
      "14606/14606 [==============================] - 0s 10us/sample - loss: 0.4574 - binary_accuracy: 0.7814 - val_loss: 0.4944 - val_binary_accuracy: 0.7700\n",
      "Epoch 28/30\n",
      "14606/14606 [==============================] - 0s 10us/sample - loss: 0.4561 - binary_accuracy: 0.7858 - val_loss: 0.4757 - val_binary_accuracy: 0.7637\n",
      "Epoch 29/30\n",
      "14606/14606 [==============================] - 0s 10us/sample - loss: 0.4680 - binary_accuracy: 0.7724 - val_loss: 0.4720 - val_binary_accuracy: 0.7716\n",
      "Epoch 30/30\n",
      "14606/14606 [==============================] - 0s 10us/sample - loss: 0.4614 - binary_accuracy: 0.7767 - val_loss: 0.4835 - val_binary_accuracy: 0.7678\n",
      "F1 in the test set: \n",
      " 0.1287120787641079\n",
      "ACC in the test set: \n",
      " 0.9181517407323859\n",
      "CM in the test set: \n",
      " [[121301   1197]\n",
      " [  9688    804]]\n",
      "positive_sample:  1365 ; negative sample:  1708\n",
      "Train on 2458 samples, validate on 615 samples\n",
      "Epoch 1/30\n",
      "2458/2458 [==============================] - 1s 379us/sample - loss: 1.2307 - binary_accuracy: 0.4967 - val_loss: 0.6845 - val_binary_accuracy: 0.5561\n",
      "Epoch 2/30\n",
      "2458/2458 [==============================] - 0s 16us/sample - loss: 0.6763 - binary_accuracy: 0.5700 - val_loss: 0.8636 - val_binary_accuracy: 0.6065\n",
      "Epoch 3/30\n",
      "2458/2458 [==============================] - 0s 16us/sample - loss: 0.7843 - binary_accuracy: 0.6310 - val_loss: 1.4290 - val_binary_accuracy: 0.5967\n",
      "Epoch 4/30\n",
      "2458/2458 [==============================] - 0s 17us/sample - loss: 0.6134 - binary_accuracy: 0.6876 - val_loss: 0.6251 - val_binary_accuracy: 0.6130\n",
      "Epoch 5/30\n",
      "2458/2458 [==============================] - 0s 16us/sample - loss: 0.5616 - binary_accuracy: 0.7160 - val_loss: 1.5332 - val_binary_accuracy: 0.6179\n",
      "Epoch 6/30\n",
      "2458/2458 [==============================] - 0s 16us/sample - loss: 0.5565 - binary_accuracy: 0.7189 - val_loss: 0.6006 - val_binary_accuracy: 0.6504\n",
      "Epoch 7/30\n",
      "2458/2458 [==============================] - 0s 16us/sample - loss: 0.5550 - binary_accuracy: 0.7201 - val_loss: 0.5885 - val_binary_accuracy: 0.6407\n",
      "Epoch 8/30\n",
      "2458/2458 [==============================] - 0s 16us/sample - loss: 0.5325 - binary_accuracy: 0.7144 - val_loss: 0.9114 - val_binary_accuracy: 0.6341\n",
      "Epoch 9/30\n",
      "2458/2458 [==============================] - 0s 16us/sample - loss: 0.5235 - binary_accuracy: 0.7295 - val_loss: 0.6785 - val_binary_accuracy: 0.6439\n",
      "Epoch 10/30\n",
      "2458/2458 [==============================] - 0s 15us/sample - loss: 0.5140 - binary_accuracy: 0.7315 - val_loss: 0.7397 - val_binary_accuracy: 0.6520\n",
      "Epoch 11/30\n",
      "2458/2458 [==============================] - 0s 16us/sample - loss: 0.5110 - binary_accuracy: 0.7295 - val_loss: 0.6303 - val_binary_accuracy: 0.6894\n",
      "Epoch 12/30\n",
      "2458/2458 [==============================] - 0s 16us/sample - loss: 0.5167 - binary_accuracy: 0.7266 - val_loss: 0.5441 - val_binary_accuracy: 0.7220\n",
      "Epoch 13/30\n",
      "2458/2458 [==============================] - 0s 15us/sample - loss: 0.5130 - binary_accuracy: 0.7290 - val_loss: 0.5632 - val_binary_accuracy: 0.7122\n",
      "Epoch 14/30\n",
      "2458/2458 [==============================] - 0s 16us/sample - loss: 0.5232 - binary_accuracy: 0.7234 - val_loss: 0.5854 - val_binary_accuracy: 0.6976\n",
      "Epoch 15/30\n",
      "2458/2458 [==============================] - 0s 17us/sample - loss: 0.5233 - binary_accuracy: 0.7213 - val_loss: 0.5392 - val_binary_accuracy: 0.7268\n",
      "Epoch 16/30\n",
      "2458/2458 [==============================] - 0s 17us/sample - loss: 0.5020 - binary_accuracy: 0.7368 - val_loss: 0.5415 - val_binary_accuracy: 0.7317\n",
      "Epoch 17/30\n",
      "2458/2458 [==============================] - 0s 15us/sample - loss: 0.5024 - binary_accuracy: 0.7376 - val_loss: 0.5083 - val_binary_accuracy: 0.7252\n",
      "Epoch 18/30\n",
      "2458/2458 [==============================] - 0s 17us/sample - loss: 0.5066 - binary_accuracy: 0.7254 - val_loss: 0.5035 - val_binary_accuracy: 0.7285\n",
      "Epoch 19/30\n",
      "2458/2458 [==============================] - 0s 15us/sample - loss: 0.5062 - binary_accuracy: 0.7286 - val_loss: 0.5240 - val_binary_accuracy: 0.7285\n",
      "Epoch 20/30\n",
      "2458/2458 [==============================] - 0s 16us/sample - loss: 0.4984 - binary_accuracy: 0.7396 - val_loss: 0.5156 - val_binary_accuracy: 0.7285\n",
      "Epoch 21/30\n",
      "2458/2458 [==============================] - 0s 16us/sample - loss: 0.4930 - binary_accuracy: 0.7429 - val_loss: 0.5111 - val_binary_accuracy: 0.7431\n",
      "Epoch 22/30\n",
      "2458/2458 [==============================] - 0s 16us/sample - loss: 0.4997 - binary_accuracy: 0.7453 - val_loss: 0.5310 - val_binary_accuracy: 0.7220\n",
      "Epoch 23/30\n",
      "2458/2458 [==============================] - 0s 15us/sample - loss: 0.4955 - binary_accuracy: 0.7400 - val_loss: 0.5079 - val_binary_accuracy: 0.7333\n",
      "Epoch 24/30\n",
      "2458/2458 [==============================] - 0s 16us/sample - loss: 0.4911 - binary_accuracy: 0.7486 - val_loss: 0.5087 - val_binary_accuracy: 0.7366\n",
      "Epoch 25/30\n",
      "2458/2458 [==============================] - 0s 16us/sample - loss: 0.4837 - binary_accuracy: 0.7474 - val_loss: 0.5021 - val_binary_accuracy: 0.7415\n",
      "Epoch 26/30\n",
      "2458/2458 [==============================] - 0s 15us/sample - loss: 0.4801 - binary_accuracy: 0.7555 - val_loss: 0.4985 - val_binary_accuracy: 0.7561\n",
      "Epoch 27/30\n",
      "2458/2458 [==============================] - 0s 15us/sample - loss: 0.4852 - binary_accuracy: 0.7461 - val_loss: 0.4990 - val_binary_accuracy: 0.7431\n",
      "Epoch 28/30\n",
      "2458/2458 [==============================] - 0s 16us/sample - loss: 0.5053 - binary_accuracy: 0.7396 - val_loss: 0.5230 - val_binary_accuracy: 0.7171\n",
      "Epoch 29/30\n",
      "2458/2458 [==============================] - 0s 16us/sample - loss: 0.5019 - binary_accuracy: 0.7404 - val_loss: 0.4882 - val_binary_accuracy: 0.7480\n",
      "Epoch 30/30\n",
      "2458/2458 [==============================] - 0s 16us/sample - loss: 0.4957 - binary_accuracy: 0.7535 - val_loss: 0.5334 - val_binary_accuracy: 0.7073\n",
      "F1 in the test set: \n",
      " 0.032177990254665806\n",
      "ACC in the test set: \n",
      " 0.9208436724565757\n",
      "CM in the test set: \n",
      " [[122288    210]\n",
      " [ 10317    175]]\n",
      "positive_sample:  1040 ; negative sample:  1302\n",
      "Train on 1873 samples, validate on 469 samples\n",
      "Epoch 1/30\n",
      "1873/1873 [==============================] - 1s 491us/sample - loss: 1.6791 - binary_accuracy: 0.5670 - val_loss: 0.6920 - val_binary_accuracy: 0.4435\n",
      "Epoch 2/30\n",
      "1873/1873 [==============================] - 0s 16us/sample - loss: 0.6661 - binary_accuracy: 0.5307 - val_loss: 2.7903 - val_binary_accuracy: 0.5714\n",
      "Epoch 3/30\n",
      "1873/1873 [==============================] - 0s 17us/sample - loss: 0.5940 - binary_accuracy: 0.6978 - val_loss: 0.6958 - val_binary_accuracy: 0.6226\n",
      "Epoch 4/30\n",
      "1873/1873 [==============================] - 0s 17us/sample - loss: 0.5238 - binary_accuracy: 0.7480 - val_loss: 2.3063 - val_binary_accuracy: 0.6034\n",
      "Epoch 5/30\n",
      "1873/1873 [==============================] - 0s 17us/sample - loss: 0.4773 - binary_accuracy: 0.7640 - val_loss: 1.2188 - val_binary_accuracy: 0.6141\n",
      "Epoch 6/30\n",
      "1873/1873 [==============================] - 0s 17us/sample - loss: 0.4295 - binary_accuracy: 0.7795 - val_loss: 1.7045 - val_binary_accuracy: 0.6098\n",
      "Epoch 7/30\n",
      "1873/1873 [==============================] - 0s 17us/sample - loss: 0.3885 - binary_accuracy: 0.8019 - val_loss: 2.9159 - val_binary_accuracy: 0.6141\n",
      "Epoch 8/30\n",
      "1873/1873 [==============================] - 0s 17us/sample - loss: 0.3752 - binary_accuracy: 0.8345 - val_loss: 1.2618 - val_binary_accuracy: 0.6930\n",
      "Epoch 9/30\n",
      "1873/1873 [==============================] - 0s 16us/sample - loss: 0.3760 - binary_accuracy: 0.8302 - val_loss: 1.1799 - val_binary_accuracy: 0.6802\n",
      "Epoch 10/30\n",
      "1873/1873 [==============================] - 0s 17us/sample - loss: 0.3989 - binary_accuracy: 0.8281 - val_loss: 0.7661 - val_binary_accuracy: 0.6631\n",
      "Epoch 11/30\n",
      "1873/1873 [==============================] - 0s 17us/sample - loss: 0.3742 - binary_accuracy: 0.8377 - val_loss: 1.1007 - val_binary_accuracy: 0.6631\n",
      "Epoch 12/30\n",
      "1873/1873 [==============================] - 0s 17us/sample - loss: 0.3210 - binary_accuracy: 0.8430 - val_loss: 1.6116 - val_binary_accuracy: 0.6695\n",
      "Epoch 13/30\n",
      "1873/1873 [==============================] - 0s 16us/sample - loss: 0.3425 - binary_accuracy: 0.8452 - val_loss: 0.4625 - val_binary_accuracy: 0.7420\n",
      "Epoch 14/30\n",
      "1873/1873 [==============================] - 0s 17us/sample - loss: 0.3873 - binary_accuracy: 0.7907 - val_loss: 0.4514 - val_binary_accuracy: 0.7505\n",
      "Epoch 15/30\n",
      "1873/1873 [==============================] - 0s 17us/sample - loss: 0.3601 - binary_accuracy: 0.8243 - val_loss: 0.8249 - val_binary_accuracy: 0.6972\n",
      "Epoch 16/30\n",
      "1873/1873 [==============================] - 0s 18us/sample - loss: 0.3269 - binary_accuracy: 0.8510 - val_loss: 0.6735 - val_binary_accuracy: 0.7164\n",
      "Epoch 17/30\n",
      "1873/1873 [==============================] - 0s 18us/sample - loss: 0.2920 - binary_accuracy: 0.8719 - val_loss: 0.5713 - val_binary_accuracy: 0.7164\n",
      "Epoch 18/30\n",
      "1873/1873 [==============================] - 0s 17us/sample - loss: 0.2931 - binary_accuracy: 0.8703 - val_loss: 0.5584 - val_binary_accuracy: 0.7143\n",
      "Epoch 19/30\n",
      "1873/1873 [==============================] - 0s 17us/sample - loss: 0.3014 - binary_accuracy: 0.8425 - val_loss: 0.5164 - val_binary_accuracy: 0.7633\n",
      "Epoch 20/30\n",
      "1873/1873 [==============================] - 0s 16us/sample - loss: 0.3205 - binary_accuracy: 0.8430 - val_loss: 0.4749 - val_binary_accuracy: 0.7228\n",
      "Epoch 21/30\n",
      "1873/1873 [==============================] - 0s 16us/sample - loss: 0.3437 - binary_accuracy: 0.8409 - val_loss: 0.4752 - val_binary_accuracy: 0.7484\n",
      "Epoch 22/30\n",
      "1873/1873 [==============================] - 0s 17us/sample - loss: 0.3382 - binary_accuracy: 0.8430 - val_loss: 0.5181 - val_binary_accuracy: 0.7420\n",
      "Epoch 23/30\n",
      "1873/1873 [==============================] - 0s 17us/sample - loss: 0.2715 - binary_accuracy: 0.8671 - val_loss: 0.5832 - val_binary_accuracy: 0.7783\n",
      "Epoch 24/30\n",
      "1873/1873 [==============================] - 0s 17us/sample - loss: 0.2600 - binary_accuracy: 0.8825 - val_loss: 0.5180 - val_binary_accuracy: 0.7484\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1873/1873 [==============================] - 0s 18us/sample - loss: 0.2686 - binary_accuracy: 0.8927 - val_loss: 0.4426 - val_binary_accuracy: 0.7868\n",
      "Epoch 26/30\n",
      "1873/1873 [==============================] - 0s 17us/sample - loss: 0.3335 - binary_accuracy: 0.8548 - val_loss: 0.5467 - val_binary_accuracy: 0.7228\n",
      "Epoch 27/30\n",
      "1873/1873 [==============================] - 0s 17us/sample - loss: 0.3863 - binary_accuracy: 0.8441 - val_loss: 0.4766 - val_binary_accuracy: 0.7292\n",
      "Epoch 28/30\n",
      "1873/1873 [==============================] - 0s 18us/sample - loss: 0.3163 - binary_accuracy: 0.8681 - val_loss: 0.4936 - val_binary_accuracy: 0.7761\n",
      "Epoch 29/30\n",
      "1873/1873 [==============================] - 0s 17us/sample - loss: 0.2765 - binary_accuracy: 0.8783 - val_loss: 0.4501 - val_binary_accuracy: 0.7783\n",
      "Epoch 30/30\n",
      "1873/1873 [==============================] - 0s 16us/sample - loss: 0.2764 - binary_accuracy: 0.8729 - val_loss: 0.5044 - val_binary_accuracy: 0.7420\n",
      "F1 in the test set: \n",
      " 0.0011419870574800152\n",
      "ACC in the test set: \n",
      " 0.9210767726896759\n",
      "CM in the test set: \n",
      " [[122488     10]\n",
      " [ 10486      6]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    X_train, y_train = get_train_data(i)\n",
    "    model_clf = build_model_clf()\n",
    "    model_clf.fit(X_train, y_train, epochs=epochs, batch_size = batch_size, validation_split=0.2, shuffle=True)\n",
    "    model_zoo[ \">10**%d\"%i] = model_clf \n",
    "    y_test_ = (y_test_log > i)\n",
    "    \n",
    "    print( \"F1 in the test set: \\n\", f1_score( clf.predict(X_test), y_test_))\n",
    "    print( \"ACC in the test set: \\n\", accuracy_score( clf.predict(X_test), y_test_))\n",
    "    print( \"CM in the test set: \\n\", confusion_matrix( clf.predict(X_test), y_test_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generally worse than Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 1.94620e+04, 2.86000e+02, ..., 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       [0.00000e+00, 6.18800e+03, 2.98700e+03, ..., 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       [0.00000e+00, 3.30000e+02, 1.13000e+02, ..., 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       ...,\n",
       "       [0.00000e+00, 6.14500e+03, 4.28600e+03, ..., 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       [1.00000e+00, 1.01836e+05, 2.48189e+05, ..., 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       [0.00000e+00, 2.87200e+03, 3.37800e+03, ..., 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data_regr(i):\n",
    "    \"\"\"\n",
    "    i in [0, 1,2,3]\n",
    "    i = 0 ==> y in [0, 10]\n",
    "    i = 1 ==> y in [10, 100]\n",
    "    i = 2 ==> y in [100, inf]\n",
    "    \"\"\"\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "    if i < 2:\n",
    "        for x, y in zip(X_train_1, y_train_1):\n",
    "            y_log =  int(np.log10(y)) if y > 0 else 0\n",
    "            if y_log == i:\n",
    "                X.append(x)\n",
    "                Y.append(y)\n",
    "    else:\n",
    "        for x, y in zip(X_train_1, y_train_1):\n",
    "            y_log =  int(np.log10(y)) if y > 0 else 0\n",
    "            if y_log >= 2:\n",
    "                X.append(x)\n",
    "                Y.append(y)\n",
    "        \n",
    "    \n",
    "    print(\"number of samples \", len(Y))\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples  50436\n"
     ]
    }
   ],
   "source": [
    "X_, y_ = get_train_data_regr(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12., 37., 56., ..., 44., 38., 41.])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples  185174\n",
      "mae on validation set:  1.268971786591297\n",
      "number of samples  50436\n",
      "mae on validation set:  18.494831651203626\n",
      "number of samples  29899\n",
      "mae on validation set:  3398.4941853853757\n"
     ]
    }
   ],
   "source": [
    "regr_zoo = {}\n",
    "\n",
    "for i in range(3):\n",
    "    X_r, y_r = get_train_data_regr(i)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_r, y_r, test_size=0.2, random_state=42)\n",
    "    regr = LinearRegression(normalize=True).fit(X_train, y_train)\n",
    "    regr_zoo[i] = regr\n",
    "    \n",
    "    print(\"mae on validation set: \", np.abs(regr.predict(X_val) - y_val).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae on validation set:  530.2997174124213\n"
     ]
    }
   ],
   "source": [
    "# Base regressor \n",
    "\n",
    "regr = LinearRegression().fit(X_train_1, y_train_1)\n",
    "print(\"mae on validation set: \", np.abs(regr.predict(X_train_1) - y_train_1).mean())\n",
    "regr_zoo[2] = regr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very bad score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_regression(X_val, y_val, threshold):\n",
    "    y_predict = np.zeros(y_val.shape[0])\n",
    "    \n",
    "    count = 0\n",
    "    for (i, x) in enumerate(X_val):\n",
    "        if (i % 2000 == 0):\n",
    "            print(\"processed: \", i)\n",
    "        p = get_classes_pos(x)\n",
    "#         print(p)\n",
    "        if p[0] > 0:\n",
    "            y_predict[i] = 0\n",
    "        else:\n",
    "            largest_class = 0\n",
    "            for j in range(2):\n",
    "                if p[j+1] >= threshold[j]:\n",
    "                    largest_class = j+1\n",
    "            if largest_class == 2:\n",
    "                count+= 1\n",
    "            y_predict[i] = max( regr_zoo[largest_class].predict(np.array([x])).squeeze(), 0)\n",
    "\n",
    "            \n",
    "#             y_predict[i] = max( regr.predict([x])[0], 0)\n",
    "            \n",
    "    cost = np.abs(y_val - y_predict).mean()\n",
    "    print(\"cost at \", threshold, \": \", cost)\n",
    "    print(count)\n",
    "    return cost, y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_val = X_test[:10000]\n",
    "y_val = y_test[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed:  0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-231-0201b99bd3fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvalidate_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-229-04d97e3dc628>\u001b[0m in \u001b[0;36mvalidate_regression\u001b[1;34m(X_val, y_val, threshold)\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlargest_class\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[0mcount\u001b[0m\u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0my_predict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mregr_zoo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlargest_class\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "validate_regression(X_val, y_val, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151.6632"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(2.9161904, dtype=float32)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = X_test[0]\n",
    "max( model.predict(np.array([x])).squeeze(), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples  185174\n",
      "mae on validation set:  1.1469462499898366\n",
      "number of samples  50436\n",
      "mae on validation set:  17.926101298331808\n",
      "number of samples  29899\n",
      "mae on validation set:  3035.5588778517194\n"
     ]
    }
   ],
   "source": [
    "regr_zoo = {}\n",
    "\n",
    "for i in range(3):\n",
    "    X_r, y_r = get_train_data_regr(i)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_r, y_r, test_size=0.2, random_state=42)\n",
    "    regr = RandomForestRegressor(max_depth=10).fit(X_train, y_train)\n",
    "    regr_zoo[i] = regr\n",
    "    \n",
    "    print(\"mae on validation set: \", np.abs(regr.predict(X_val) - y_val).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae on validation set:  408.29171275405116\n"
     ]
    }
   ],
   "source": [
    "# Base regressor \n",
    "\n",
    "regr = RandomForestRegressor(max_depth=10).fit(X_train_1, y_train_1)\n",
    "print(\"mae on validation set: \", np.abs(regr.predict(X_train_1) - y_train_1).mean())\n",
    "regr_zoo[2] = regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed:  0\n",
      "processed:  2000\n",
      "processed:  4000\n",
      "processed:  6000\n",
      "processed:  8000\n",
      "cost at  [0.47092152, 0.55543368, 1, 1, 1] :  165.58232495075643\n",
      "1019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(165.58232495075643,\n",
       " array([3.38864043e+00, 1.32338926e-01, 0.00000000e+00, ...,\n",
       "        3.64975534e-01, 5.32437904e+02, 0.00000000e+00]))"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_val = X_test[:10000]\n",
    "y_val = y_test[:10000]\n",
    "\n",
    "validate_regression(X_val, y_val, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151.6632"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Slightly better than before, still worse than all-0 prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The base regressor does not work well, we try to replace it by a deep learning regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=1e-2,\n",
    "        decay_steps=10000,\n",
    "        decay_rate=0.95)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, 'relu'))\n",
    "    \n",
    "    model.compile(loss=\"mae\", optimizer=optimizer, metrics=[\"mae\"])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 212407 samples, validate on 53102 samples\n",
      "Epoch 1/10\n",
      "212407/212407 [==============================] - 4s 20us/sample - loss: 290.1659 - mae: 290.1660 - val_loss: 303.0263 - val_mae: 303.0262\n",
      "Epoch 2/10\n",
      "212407/212407 [==============================] - 2s 12us/sample - loss: 288.7314 - mae: 288.7313 - val_loss: 300.1517 - val_mae: 300.1517\n",
      "Epoch 3/10\n",
      "212407/212407 [==============================] - 2s 12us/sample - loss: 287.8366 - mae: 287.8365 - val_loss: 299.3631 - val_mae: 299.3631\n",
      "Epoch 4/10\n",
      "212407/212407 [==============================] - 2s 12us/sample - loss: 286.4051 - mae: 286.4050 - val_loss: 300.2361 - val_mae: 300.2360\n",
      "Epoch 5/10\n",
      "212407/212407 [==============================] - 2s 12us/sample - loss: 286.3894 - mae: 286.3893 - val_loss: 299.2922 - val_mae: 299.2921\n",
      "Epoch 6/10\n",
      "212407/212407 [==============================] - 2s 12us/sample - loss: 285.8466 - mae: 285.8465 - val_loss: 307.4794 - val_mae: 307.4794\n",
      "Epoch 7/10\n",
      "212407/212407 [==============================] - 3s 12us/sample - loss: 286.8834 - mae: 286.8835 - val_loss: 301.6784 - val_mae: 301.6784\n",
      "Epoch 8/10\n",
      "212407/212407 [==============================] - 3s 12us/sample - loss: 286.2255 - mae: 286.2256 - val_loss: 299.2519 - val_mae: 299.2519\n",
      "Epoch 9/10\n",
      "212407/212407 [==============================] - 3s 12us/sample - loss: 285.6221 - mae: 285.6220 - val_loss: 297.6704 - val_mae: 297.6704\n",
      "Epoch 10/10\n",
      "212407/212407 [==============================] - 2s 11us/sample - loss: 285.5020 - mae: 285.5020 - val_loss: 299.1216 - val_mae: 299.1216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x231350c0e10>"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 512\n",
    "model = build_model()\n",
    "model.fit(X_train_1, y_train_1, epochs=epochs, batch_size = batch_size, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287.45823157818137"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs( model.predict(X_train_1).squeeze() - y_train_1 ).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error on train data is the closer to the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_zoo[2] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed:  0\n",
      "processed:  2000\n",
      "processed:  4000\n",
      "processed:  6000\n",
      "processed:  8000\n",
      "cost at  [0.47092152, 0.55543368, 1, 1, 1] :  147.83890364064425\n",
      "1019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(147.83890364064425,\n",
       " array([3.38864043, 0.13233893, 0.        , ..., 0.36497553, 3.19536519,\n",
       "        0.        ]))"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_val = X_test[:10000]\n",
    "y_val = y_test[:10000]\n",
    "\n",
    "validate_regression(X_val, y_val, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforced Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_secondary_y(X, y, regr):\n",
    "    \"\"\"\n",
    "        get the difference between the predict of the regr on X and y\n",
    "    \"\"\"\n",
    "    return y - np.clip(regr.predict(X).squeeze(), 0, 10**7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(665777, 21)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(265509, 21)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_secondary = get_secondary_y(X_train_1, y_train_1, regr_zoo[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   249.,    390.,    606.,   1322.,  74961., 135033.,  11345.,\n",
       "          5964.,   3940.,   2862.]),\n",
       " array([-9.99849854e+01, -7.99890877e+01, -5.99931900e+01, -3.99972923e+01,\n",
       "        -2.00013947e+01, -5.49697876e-03,  1.99904007e+01,  3.99862984e+01,\n",
       "         5.99821960e+01,  7.99780937e+01,  9.99739914e+01]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD6CAYAAAC/KwBlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAXgklEQVR4nO3df6zd9X3f8edrdkNJUogBw6hNZqe4WQFtS7gidFmjSM7A+bGYbbDdaB3WaskqoluyrWphSCNKZCmsa1lRBhUrDMMywKOJsJow4kKzaBKBXAgJGEK5CRQcHOzWjLB10Jq+98f53Oz4cu7Hvj98r4HnQzo63/P+fj/f8z7fc69f9/vjHKeqkCRpJn9lqRuQJB3dDApJUpdBIUnqMigkSV0GhSSpy6CQJHUdMiiS3Jhkb5JHR8z71SSV5KSh2uVJJpM8keT8ofrZSR5p865JklY/JsntrX5/kjVDYzYlebLdNs33xUqSZm/5YSxzE/B54ObhYpLTgL8LPDNUOwMYB84Efhr4gyQ/W1WvAtcBW4BvAF8BNgB3AZuBF6rq9CTjwFXAP05yAnAlMAYU8GCSHVX1Qq/Zk046qdasWXMYL0uSNOXBBx/8k6paOWreIYOiqr4+/Ff+kKuBXwPuHKptBG6rqleAp5JMAuckeRo4rqruA0hyM3ABg6DYCHy6jb8D+Hzb2zgf2FlV+9uYnQzC5dZev2vWrGFiYuJQL0uSNCTJH880b07nKJJ8HPhBVX172qxVwLNDj3e32qo2Pb1+0JiqOgC8CJzYWZckaREdzqGngyR5K3AFcN6o2SNq1anPdcz0nrYwOKzFO9/5zlGLSJLmaC57FD8DrAW+3Q4prQYeSvJXGfzVf9rQsquB51p99Yg6w2OSLAeOB/Z31vUaVXV9VY1V1djKlSMPsUmS5mjWQVFVj1TVyVW1pqrWMPgH/b1V9UNgBzDermRaC6wDHqiqPcBLSc5t5x8u5v+f29gBTF3RdCFwbw2+qfBu4LwkK5KsYLAHc/fcX6okaS4Oeegpya3AB4GTkuwGrqyqG0YtW1W7kmwHHgMOAJe2K54ALmFwBdWxDE5i39XqNwC3tBPf+xlcNUVV7U/yWeCbbbnPTJ3YliQtnrzRvmZ8bGysvOpJkmYnyYNVNTZqnp/MliR1GRSSpC6DQpLUNevPUUiauzWXfXlJnvfpz310SZ5XbwzuUUiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUtchgyLJjUn2Jnl0qPYbSb6b5DtJvpTkHUPzLk8ymeSJJOcP1c9O8kibd02StPoxSW5v9fuTrBkasynJk+22aaFetCTp8B3OHsVNwIZptZ3AWVX1N4A/Ai4HSHIGMA6c2cZcm2RZG3MdsAVY125T69wMvFBVpwNXA1e1dZ0AXAm8DzgHuDLJitm/REnSfBwyKKrq68D+abWvVtWB9vAbwOo2vRG4rapeqaqngEngnCSnAsdV1X1VVcDNwAVDY7a16TuA9W1v43xgZ1Xtr6oXGITT9MCSJB1hC3GO4peAu9r0KuDZoXm7W21Vm55eP2hMC58XgRM765IkLaJ5BUWSK4ADwBemSiMWq059rmOm97ElyUSSiX379vWbliTNypyDop1c/hjwT9rhJBj81X/a0GKrgedaffWI+kFjkiwHjmdwqGumdb1GVV1fVWNVNbZy5cq5viRJ0ghzCookG4BfBz5eVX82NGsHMN6uZFrL4KT1A1W1B3gpybnt/MPFwJ1DY6auaLoQuLcFz93AeUlWtJPY57WaJGkRLT/UAkluBT4InJRkN4MrkS4HjgF2tqtcv1FVv1xVu5JsBx5jcEjq0qp6ta3qEgZXUB3L4JzG1HmNG4Bbkkwy2JMYB6iq/Uk+C3yzLfeZqjropLok6cg7ZFBU1SdGlG/oLL8V2DqiPgGcNaL+MnDRDOu6EbjxUD1Kko4cP5ktSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUdcigSHJjkr1JHh2qnZBkZ5In2/2KoXmXJ5lM8kSS84fqZyd5pM27Jkla/Zgkt7f6/UnWDI3Z1J7jySSbFupFS5IO3+HsUdwEbJhWuwy4p6rWAfe0xyQ5AxgHzmxjrk2yrI25DtgCrGu3qXVuBl6oqtOBq4Gr2rpOAK4E3gecA1w5HEiSpMVxyKCoqq8D+6eVNwLb2vQ24IKh+m1V9UpVPQVMAuckORU4rqruq6oCbp42ZmpddwDr297G+cDOqtpfVS8AO3ltYEmSjrC5nqM4par2ALT7k1t9FfDs0HK7W21Vm55eP2hMVR0AXgRO7KzrNZJsSTKRZGLfvn1zfEmSpFEW+mR2RtSqU5/rmIOLVddX1VhVja1cufKwGpUkHZ65BsXz7XAS7X5vq+8GThtabjXwXKuvHlE/aEyS5cDxDA51zbQuSdIimmtQ7ACmrkLaBNw5VB9vVzKtZXDS+oF2eOqlJOe28w8XTxszta4LgXvbeYy7gfOSrGgnsc9rNUnSIlp+qAWS3Ap8EDgpyW4GVyJ9DtieZDPwDHARQFXtSrIdeAw4AFxaVa+2VV3C4AqqY4G72g3gBuCWJJMM9iTG27r2J/ks8M223GeqavpJdUnSEXbIoKiqT8wwa/0My28Fto6oTwBnjai/TAuaEfNuBG48VI+SpCPHT2ZLkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqWteQZHkXybZleTRJLcm+ckkJyTZmeTJdr9iaPnLk0wmeSLJ+UP1s5M80uZdkyStfkyS21v9/iRr5tOvJGn25hwUSVYB/wIYq6qzgGXAOHAZcE9VrQPuaY9JckabfyawAbg2ybK2uuuALcC6dtvQ6puBF6rqdOBq4Kq59itJmpv5HnpaDhybZDnwVuA5YCOwrc3fBlzQpjcCt1XVK1X1FDAJnJPkVOC4qrqvqgq4edqYqXXdAayf2tuQJC2OOQdFVf0A+PfAM8Ae4MWq+ipwSlXtacvsAU5uQ1YBzw6tYnerrWrT0+sHjamqA8CLwIlz7VmSNHvzOfS0gsFf/GuBnwbeluQXe0NG1KpT742Z3suWJBNJJvbt29dvXJI0K/M59PQh4Kmq2ldVfwF8EfjbwPPtcBLtfm9bfjdw2tD41QwOVe1u09PrB41ph7eOB/ZPb6Sqrq+qsaoaW7ly5TxekiRpuvkExTPAuUne2s4brAceB3YAm9oym4A72/QOYLxdybSWwUnrB9rhqZeSnNvWc/G0MVPruhC4t53HkCQtkuVzHVhV9ye5A3gIOAB8C7geeDuwPclmBmFyUVt+V5LtwGNt+Uur6tW2ukuAm4BjgbvaDeAG4JYkkwz2JMbn2q8kaW7mHBQAVXUlcOW08isM9i5GLb8V2DqiPgGcNaL+Mi1oJElLw09mS5K6DApJUpdBIUnqmtc5Cun1aM1lX17qFqTXFfcoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUpdBIUnqMigkSV0GhSSpa15BkeQdSe5I8t0kjyf5+SQnJNmZ5Ml2v2Jo+cuTTCZ5Isn5Q/WzkzzS5l2TJK1+TJLbW/3+JGvm068kafbmu0fx28B/r6q/DvxN4HHgMuCeqloH3NMek+QMYBw4E9gAXJtkWVvPdcAWYF27bWj1zcALVXU6cDVw1Tz7lSTN0pyDIslxwAeAGwCq6s+r6n8BG4FtbbFtwAVteiNwW1W9UlVPAZPAOUlOBY6rqvuqqoCbp42ZWtcdwPqpvQ1J0uKYzx7Fu4B9wH9O8q0kv5vkbcApVbUHoN2f3JZfBTw7NH53q61q09PrB42pqgPAi8CJ8+hZkjRL8wmK5cB7geuq6j3A/6EdZprBqD2B6tR7Yw5ecbIlyUSSiX379vW7liTNynyCYjewu6rub4/vYBAcz7fDSbT7vUPLnzY0fjXwXKuvHlE/aEyS5cDxwP7pjVTV9VU1VlVjK1eunMdLkiRNN+egqKofAs8meXcrrQceA3YAm1ptE3Bnm94BjLcrmdYyOGn9QDs89VKSc9v5h4unjZla14XAve08hiRpkSyf5/h/DnwhyVuA7wP/jEH4bE+yGXgGuAigqnYl2c4gTA4Al1bVq209lwA3AccCd7UbDE6U35JkksGexPg8+5UkzdK8gqKqHgbGRsxaP8PyW4GtI+oTwFkj6i/TgkaStDT8ZLYkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSugwKSVLXvIMiybIk30ry++3xCUl2Jnmy3a8YWvbyJJNJnkhy/lD97CSPtHnXJEmrH5Pk9la/P8ma+fYrSZqdhdij+CTw+NDjy4B7qmodcE97TJIzgHHgTGADcG2SZW3MdcAWYF27bWj1zcALVXU6cDVw1QL0K0mahXkFRZLVwEeB3x0qbwS2teltwAVD9duq6pWqegqYBM5JcipwXFXdV1UF3DxtzNS67gDWT+1tSJIWx3z3KP4D8GvAXw7VTqmqPQDt/uRWXwU8O7Tc7lZb1aan1w8aU1UHgBeBE6c3kWRLkokkE/v27ZvnS5IkDZtzUCT5GLC3qh483CEjatWp98YcXKi6vqrGqmps5cqVh9mOJOlwLJ/H2PcDH0/yEeAngeOS/Bfg+SSnVtWedlhpb1t+N3Da0PjVwHOtvnpEfXjM7iTLgeOB/fPoWZI0S3Peo6iqy6tqdVWtYXCS+t6q+kVgB7CpLbYJuLNN7wDG25VMaxmctH6gHZ56Kcm57fzDxdPGTK3rwvYcr9mjkCQdOfPZo5jJ54DtSTYDzwAXAVTVriTbgceAA8ClVfVqG3MJcBNwLHBXuwHcANySZJLBnsT4EehXktSxIEFRVV8Dvtam/xRYP8NyW4GtI+oTwFkj6i/TgkaStDT8ZLYkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSuuYcFElOS/KHSR5PsivJJ1v9hCQ7kzzZ7lcMjbk8yWSSJ5KcP1Q/O8kjbd41SdLqxyS5vdXvT7Jm7i9VkjQX89mjOAD866r6OeBc4NIkZwCXAfdU1TrgnvaYNm8cOBPYAFybZFlb13XAFmBdu21o9c3AC1V1OnA1cNU8+pUkzcGcg6Kq9lTVQ236JeBxYBWwEdjWFtsGXNCmNwK3VdUrVfUUMAmck+RU4Liquq+qCrh52pipdd0BrJ/a25AkLY4FOUfRDgm9B7gfOKWq9sAgTICT22KrgGeHhu1utVVtenr9oDFVdQB4EThxIXqWJB2eeQdFkrcDvwd8qqp+1Ft0RK069d6Y6T1sSTKRZGLfvn2HalmSNAvzCookP8EgJL5QVV9s5efb4STa/d5W3w2cNjR8NfBcq68eUT9oTJLlwPHA/ul9VNX1VTVWVWMrV66cz0uSJE0zn6ueAtwAPF5VvzU0awewqU1vAu4cqo+3K5nWMjhp/UA7PPVSknPbOi+eNmZqXRcC97bzGJKkRbJ8HmPfD/xT4JEkD7favwE+B2xPshl4BrgIoKp2JdkOPMbgiqlLq+rVNu4S4CbgWOCudoNBEN2SZJLBnsT4PPqVJM3BnIOiqv4no88hAKyfYcxWYOuI+gRw1oj6y7SgkSQtDT+ZLUnqMigkSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSugwKSVLXfD6ZLel1Ys1lX16y5376cx9dsufWwnCPQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQuP3An6Yhaqg/7+UG/heMehSSpy6CQJHV56EnSG5Lfb7VwDApJWmBvtPMyr4tDT0k2JHkiyWSSy5a6H0l6MznqgyLJMuA/Ah8GzgA+keSMpe1Kkt48Xg+Hns4BJqvq+wBJbgM2Ao8taVeat6U8hizp8L0egmIV8OzQ493A+47Uk/mPlyQd7PUQFBlRq4MWSLYAW9rD/53kiXk830nAn8xj/JFiX7NjX7NjX7NzVPaVq+bV11+bacbrISh2A6cNPV4NPDe8QFVdD1y/EE+WZKKqxhZiXQvJvmbHvmbHvmbnzdbXUX8yG/gmsC7J2iRvAcaBHUvckyS9aRz1exRVdSDJrwB3A8uAG6tq1xK3JUlvGkd9UABU1VeAryzS0y3IIawjwL5mx75mx75m503VV6rq0EtJkt60Xg/nKCRJS+hNGxRJLkqyK8lfJhmbNu/y9nUhTyQ5f6h+dpJH2rxrkoy6dHche7w9ycPt9nSSh1t9TZL/OzTvd45kHyP6+nSSHww9/0eG5o3cdovU128k+W6S7yT5UpJ3tPqSbq/Ww1HxNTRJTkvyh0kebz//n2z1Gd/TRezt6fb79XCSiVY7IcnOJE+2+xWL3NO7h7bJw0l+lORTS7W9ktyYZG+SR4dqM26jBft9rKo35Q34OeDdwNeAsaH6GcC3gWOAtcD3gGVt3gPAzzP4bMddwIcXsd/fBP5tm14DPLqE2+7TwK+OqM+47Rapr/OA5W36KuCqo2R7LWvb4l3AW9o2OmOJejkVeG+b/ingj9r7NvI9XeTengZOmlb7d8Blbfqyqfd0Cd/HHzL4vMGSbC/gA8B7h3+eZ9pGC/n7+Kbdo6iqx6tq1AfzNgK3VdUrVfUUMAmck+RU4Liquq8G78LNwAWL0Wvbc/lHwK2L8XzzMHLbLdaTV9VXq+pAe/gNBp+5ORr8+GtoqurPgamvoVl0VbWnqh5q0y8BjzP49oOj1UZgW5vexiL9zs1gPfC9qvrjpWqgqr4O7J9WnmkbLdjv45s2KDpGfWXIqnbbPaK+GH4BeL6qnhyqrU3yrST/I8kvLFIfw36lHeK5cWhXd6ZttxR+icFe35Sl3F5H03b5sSRrgPcA97fSqPd0MRXw1SQPtm9bADilqvbAIOSAk5egrynjHPzH2lJvrykzbaMF+7l7QwdFkj9I8uiIW++vuZm+MuSQXyVyBHv8BAf/gO4B3llV7wH+FfBfkxw3315m0dd1wM8Af6v18ptTw0asakEvqzuc7ZXkCuAA8IVWOuLb61Btj6gt6eWGSd4O/B7wqar6ETO/p4vp/VX1XgbfFH1pkg8sQQ8jZfBh348D/62VjobtdSgL9nP3uvgcxVxV1YfmMGymrwzZzcGHMl7zVSJzcagekywH/gFw9tCYV4BX2vSDSb4H/CwwMd9+Drevof7+E/D77eEhv27lSPeVZBPwMWB9O0S4KNvrEI74dpmNJD/BICS+UFVfBKiq54fmD7+ni6aqnmv3e5N8icFhkueTnFpVe9rh372L3VfzYeChqe10NGyvITNtowX7uXtD71HM0Q5gPMkxSdYC64AH2i7dS0nObecMLgbuXIR+PgR8t6p+fNgrycoM/p8Okryr9fj9Rehl6vlPHXr494GpKzBGbrtF7GsD8OvAx6vqz4bqS7q9OIq+hqb97N4APF5VvzVUn+k9Xay+3pbkp6amGVyY8CiD7bSpLbaJxfmdG+Wgvfql3l7TzLSNFu73camuIFjqG4M3dzeDvzSfB+4emncFgysEnmDoyiZgjMEPxPeAz9M+sHiE+7wJ+OVptX8I7GJwRcNDwN9b5G13C/AI8J32w3jqobbdIvU1yeCY7MPt9jtHw/ZqPXyEwRVG3wOuWOznH+rj7zA4/PCdoe30kd57ukh9vau9P99u79UVrX4icA/wZLs/YQm22VuBPwWOH6otyfZiEFZ7gL9o/35t7m2jhfp99JPZkqQuDz1JkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1PX/ANBszgOfkv+IAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_secondary[ np.abs(y_secondary) < 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(257572,)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_secondary[ np.abs(y_secondary) < 1000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(265509,)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_secondary.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "96 % examples' absolute values are below 1000. Good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Secondary regressor: linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "407.005306585776"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(y_secondary).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "432.19795526993767"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(regr.predict(X_train_1) - y_secondary).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = LinearRegression().fit(X_train_1, y_secondary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worse than we don't have it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Secondary regressor: Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observe the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.0"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10000,) (665777,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-151-5c3780856bf9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_predict\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10000,) (665777,) "
     ]
    }
   ],
   "source": [
    "np.abs(y_predict - y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160.45703709220447"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6.22521e+05, 3.40450e+04, 2.99500e+03, 1.66900e+03, 9.17000e+02,\n",
       "        4.84000e+02, 5.71000e+02, 3.02000e+02, 2.10000e+02, 1.45000e+02,\n",
       "        1.25000e+02, 5.40000e+01, 1.10000e+01, 4.80000e+01, 3.60000e+01,\n",
       "        8.00000e+00, 8.00000e+00, 1.99000e+02, 2.56000e+02, 6.00000e+00,\n",
       "        7.00000e+00, 2.10000e+01, 9.30000e+01, 6.00000e+00, 5.00000e+00,\n",
       "        5.00000e+00, 0.00000e+00, 3.00000e+00, 9.00000e+00, 4.00000e+00,\n",
       "        1.07000e+02, 4.10000e+01, 9.00000e+00, 2.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 1.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 1.00000e+00, 3.00000e+00, 0.00000e+00, 5.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 1.60000e+01]),\n",
       " array([    0.        ,   422.94720774,   845.89441549,  1268.84162323,\n",
       "         1691.78883097,  2114.73603872,  2537.68324646,  2960.6304542 ,\n",
       "         3383.57766195,  3806.52486969,  4229.47207743,  4652.41928518,\n",
       "         5075.36649292,  5498.31370067,  5921.26090841,  6344.20811615,\n",
       "         6767.1553239 ,  7190.10253164,  7613.04973938,  8035.99694713,\n",
       "         8458.94415487,  8881.89136261,  9304.83857036,  9727.7857781 ,\n",
       "        10150.73298584, 10573.68019359, 10996.62740133, 11419.57460907,\n",
       "        11842.52181682, 12265.46902456, 12688.4162323 , 13111.36344005,\n",
       "        13534.31064779, 13957.25785553, 14380.20506328, 14803.15227102,\n",
       "        15226.09947877, 15649.04668651, 16071.99389425, 16494.941102  ,\n",
       "        16917.88830974, 17340.83551748, 17763.78272523, 18186.72993297,\n",
       "        18609.67714071, 19032.62434846, 19455.5715562 , 19878.51876394,\n",
       "        20301.46597169, 20724.41317943]),\n",
       " <a list of 49 Patch objects>)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_predict, bins=49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 91.34859026, -94.75043562, 388.61893765,  44.04919105,\n",
       "       -16.71411529, 262.77630995, 264.12108715,   7.51192508,\n",
       "       -16.21918482, -29.82701817, -18.83204253, -24.85805737,\n",
       "        83.52954733, -56.04407642,  -6.5297966 ,  -4.91947558])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=1e-3,\n",
    "        decay_steps=10000,\n",
    "        decay_rate=0.95)\n",
    "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr_schedule)\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, 'relu'))\n",
    "    \n",
    "    model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"mae\"])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8114,)"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1647.,  1767.,  8581.,  4273.,  1014.,  5650.,  9704.,  1342.,\n",
       "        1263.,  4873.,  6107.,  2340., 35745.,  5011.,  2288.,  1121.,\n",
       "        5846.,  4910., 16964.,  4822.,  1938.,  5387.,  3279.,  2789.,\n",
       "        4917.,  3407.,  2457.,  1555.,  2545.,  7901., 12308.,  4434.,\n",
       "        1670.,  1481.,  2500.,  1778.,  3020.,  1589.,  1474.,  7122.,\n",
       "       13509., 30635.,  1084., 17341.,  2762.,  1063.,  2384.,  1034.,\n",
       "        1026., 11042.,  1454.,  1259.,  4647.,  6878.,  1293.,  1595.,\n",
       "        4191.,  1221.,  2608.,  1049.,  1784.,  3286.,  1887.,  2433.,\n",
       "        8245.,  1956.,  2333.,  7230., 14286.,  4724.,  4123., 18770.,\n",
       "       16629.,  1696.,  1086.,  2140.,  4399.,  3035., 10708.,  1865.,\n",
       "        3868.,  8027.,  9972.,  7223.,  2163.,  1212.,  3116., 13196.,\n",
       "        1173.,  3088.,  3339.,  2958.,  1913.,  1662.,  1060.,  1128.,\n",
       "        7320.,  4499.,  3405.,  1497.])"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples  8114\n",
      "Train on 6491 samples, validate on 1623 samples\n",
      "Epoch 1/20\n",
      "6491/6491 [==============================] - 1s 206us/sample - loss: 532852645.7729 - mae: 8097.6880 - val_loss: 549426300.6285 - val_mae: 11397.0547\n",
      "Epoch 2/20\n",
      "6491/6491 [==============================] - 0s 26us/sample - loss: 503712518.3793 - mae: 8191.8618 - val_loss: 526856371.8546 - val_mae: 8933.3994\n",
      "Epoch 3/20\n",
      "6491/6491 [==============================] - 0s 26us/sample - loss: 501788697.7255 - mae: 8176.4209 - val_loss: 525298414.1762 - val_mae: 8482.9307\n",
      "Epoch 4/20\n",
      "6491/6491 [==============================] - 0s 26us/sample - loss: 501514196.7648 - mae: 8024.3525 - val_loss: 549978972.6087 - val_mae: 11903.4883\n",
      "Epoch 5/20\n",
      "6491/6491 [==============================] - 0s 25us/sample - loss: 499303160.0333 - mae: 8132.1084 - val_loss: 522806920.5767 - val_mae: 8620.9727\n",
      "Epoch 6/20\n",
      "5120/6491 [======================>.......] - ETA: 0s - loss: 542327694.7368 - mae: 8026.1812"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-397-d441d2148e8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_train_data_regr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 256\n",
    "model = build_model()\n",
    "X_train, y_train = get_train_data_regr(2)\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size = batch_size, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_2).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17948044.0"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192.7855864041011"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.abs((y_pred - y_test_2))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([334.72394,   0.     ,   0.     , ...,   0.     , 205.2121 ,\n",
       "         0.     ], dtype=float32)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1., 192.,   0., ...,  10.,  41.,   0.])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
